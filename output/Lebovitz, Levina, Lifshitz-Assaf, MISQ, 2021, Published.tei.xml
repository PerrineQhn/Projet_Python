<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IS AI GROUND TRUTH REALLY TRUE? THE DANGERS OF TRAINING AND EVALUATING AI TOOLS BASED ON EXPERTS&apos; KNOW-WHAT 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sarah</forename><surname>Lebovitz</surname></persName>
							<email>sarah.lebovitz@virginia.edu</email>
						</author>
						<author>
							<persName><forename type="first">Natalia</forename><surname>Levina</surname></persName>
							<email>nlevina@stern.nyu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hila</forename><surname>Lifshitz-Assaf</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Virginia</orgName>
								<orgName type="institution" key="instit2">McIntire School of Commerce</orgName>
								<address>
									<postCode>22904</postCode>
									<settlement>Charlottesville</settlement>
									<region>VA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>Stern New York</settlement>
									<region>NY</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>Stern New York</settlement>
									<region>NY</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Nicholas Berente</orgName>
								<address>
									<addrLine>Bin Gu</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Jan Recker</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">IS AI GROUND TRUTH REALLY TRUE? THE DANGERS OF TRAINING AND EVALUATING AI TOOLS BASED ON EXPERTS&apos; KNOW-WHAT 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.25300/MISQ/2021/16564</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2024-12-03T20:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Artificial intelligence</term>
					<term>evaluation</term>
					<term>uncertainty</term>
					<term>new technology</term>
					<term>professional knowledge work</term>
					<term>innovation</term>
					<term>know-how</term>
					<term>medical diagnosis</term>
					<term>ground truth</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Organizational decision-makers need to evaluate AI tools in light of increasing claims that such tools outperform human experts. Yet, measuring the quality of knowledge work is challenging, raising the question of how to evaluate AI performance in such contexts. We investigate this question through a field study of a major U.S. hospital, observing how managers evaluated five different machine-learning (ML) based AI tools. Each tool reported high performance according to standard AI accuracy measures, which were based on ground truth labels provided by qualified experts. Trying these tools out in practice, however, revealed that none of them met expectations. Searching for explanations, managers began confronting the high uncertainty of experts' know-what knowledge captured in ground truth labels used to train and validate ML models. In practice, experts address this uncertainty by drawing on rich know-how practices, which were not incorporated into these ML-based tools. Discovering the disconnect between AI's know-what and experts' know-how enabled managers to better understand the risks and benefits of each tool. This study shows dangers of treating ground truth labels used in ML models objectively when the underlying knowledge is uncertain. We outline implications of our study for developing, training, and evaluating AI for knowledge work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction 1</head><p>We are experiencing a significant shift in how knowledge is produced, from focusing on the quality of the human expert to evaluating modern artificial intelligence (AI) technologies. This raises key questions about how we evaluate the performance of human experts as compared to AI technologies. In this study, we focus on specific AI tools that use machine learning (ML) classification methods to draw inferences from training datasets consisting of labeled input-output pairs and classifies new inputs into predefined output classes. One of the challenges with the development of traditional AI tech-nologies, such as rule-based expert systems, has been that they often relied on representing experts' knowledge in machinereadable form <ref type="bibr" target="#b33">(Forsythe 1993;</ref><ref type="bibr" target="#b43">Hutchins 1995;</ref><ref type="bibr" target="#b97">Star 1989;</ref><ref type="bibr" target="#b99">Suchman 1987</ref>). This was difficult to achieve due to the tacit nature of experts' knowledge <ref type="bibr">(Brown and</ref><ref type="bibr">Duguid 1991, 2001;</ref><ref type="bibr" target="#b46">Kogut and Zander 1992;</ref><ref type="bibr" target="#b72">Orlikowski 2002)</ref>. Today, however, there is renewed hope among AI creators that they can bypass capturing tacit aspects of experts' knowledge because MLbased AI can implicitly infer how inputs map to outputs. This shift in AI technologies has prompted a burgeoning number of reports that AI can produce higher quality judgments than human experts (e.g., <ref type="bibr" target="#b41">Grady 2019;</ref><ref type="bibr" target="#b64">Moran 2018;</ref><ref type="bibr" target="#b93">Shoham et al. 2018)</ref>.</p><p>Organizational decision-makers are confronting this exploding discourse of the promises of ML-based AI and face decisions about whether and how to incorporate such tools in their organizations <ref type="bibr" target="#b29">(Faraj et al. 2018;</ref><ref type="bibr" target="#b84">Rao and Verweij 2017)</ref>. Part of assessing the quality of new technologies involves examining the reported "outperformance" claims by examining the technical objects and their implications <ref type="bibr" target="#b44">(Knorr Cetina 1999)</ref>. While recent research has begun investigating how individual users interact with AI tools in practice (e.g., <ref type="bibr" target="#b19">Christin 2020;</ref><ref type="bibr" target="#b53">Lebovitz 2019;</ref><ref type="bibr" target="#b74">Pachidi et al. 2021)</ref>, we believe it is critical to understand how managers evaluate AI tools as such evaluations drive their adoption decisions.</p><p>To this end, we conducted a field study that focuses on understanding how managers in the field of diagnostic radiology evaluated AI tools for potential organizational adoption. This study is based on the growing area of AI development for medical diagnosis, a field in which experts experience high degrees of uncertainty. Diagnostic radiology, in particular, has been at the cutting-edge of developing AI tools dating back to the 1980s (e.g., <ref type="bibr" target="#b16">Chandrasekaran et al. 1980)</ref>. Early attempts utilizing rule-based expert systems largely failed, given technical limitations at that time (Oakden-Rayner 2019), but recent technological advances (especially in MLbased tools for image recognition) are spurring renewed interest and investment in diagnostic AI tools. As a result, growing numbers of ML-based AI tools claim to outperform experts and have captured the attention of diagnostic radiology practices worldwide. Our study follows how managers within a major U.S. diagnostic radiology department evaluated five ML-based AI tools for potential adoption and the challenges they encountered. While, in practice, experts tend to rely on rich know-how (accumulated expertise, rooted in situated, social, and tacit practices) to gauge their work quality, managers' evaluation process for these AI tools focused primarily on know-what knowledge outputs (explicit and codified aspects of knowledge) represented in ground truth labels and summary accuracy measures. Although know-what-based measures suggested the AI tools were highly accurate, all five tools performed poorly during internal pilot studies and left managers searching for explanations. Their search ultimately led managers to confront the high uncertainty involved in evaluating human experts' knowledge outputs <ref type="bibr">(know-what)</ref> and to recognize that ML-based AI tools did not capture experts' tacit knowledge practices <ref type="bibr">(knowhow)</ref>. Discovering the disconnect between ML-based AI's know-what and human experts' know-how enabled managers to better understand the risks and benefits associated with each AI tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background Literature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating Professional Knowledge Work</head><p>Evaluating knowledge work is at the heart of many professional fields, yet it is highly challenging since it is far from objective. Prior sociology of science and knowledge literature has established how evaluation of knowledge occurs through ongoing processes of contestation and negotiation across and within social groups (e.g., <ref type="bibr" target="#b50">Latour 1987;</ref><ref type="bibr" target="#b79">Pinch and Bijker 1987;</ref><ref type="bibr" target="#b98">Star 1995)</ref>. Thus, experts in knowledgeintensive fields have been shown to deeply struggle to validate their novel insights, as shown by studies of scientists in biomedical innovation <ref type="bibr" target="#b25">(Dougherty and Dunne 2012;</ref><ref type="bibr" target="#b59">Mengis et al. 2018)</ref> or medical professionals <ref type="bibr" target="#b53">(Lebovitz 2019;</ref><ref type="bibr" target="#b58">Menchik 2014)</ref>: struggling amidst the uncertainty they face about the current state of medical knowledge: "what is not understood about the human body and how it functions is far greater than what is understood" <ref type="bibr">(Northrup 2005, p. 70)</ref>. Experts often acknowledge the uncertainty about knowledge in their given domain <ref type="bibr">(e.g., Knorr Cetina 1999;</ref><ref type="bibr" target="#b59">Mengis et al. 2018;</ref><ref type="bibr" target="#b87">Rindova and Courtney 2020;</ref><ref type="bibr" target="#b90">Schön 1983)</ref>, as in the medical literature discussing how many potential medical treatments or tests lack external validation or more reliable measures that can assess the quality of a given medical outcome <ref type="bibr" target="#b102">(Timmermans and Berg 2003)</ref>.</p><p>However, evaluating the quality of knowledge work requires going beyond assessing knowledge outputs, or experts' "know-what," to assessing knowledge practices, or experts' "know-how." For decades, organizational scholars have been investigating the social, tacit, and embodied nature of knowhow in knowledge work <ref type="bibr">(Brown and</ref><ref type="bibr">Duguid 1991, 2001;</ref><ref type="bibr" target="#b35">Garud 1997;</ref><ref type="bibr" target="#b43">Hutchins 1995;</ref><ref type="bibr" target="#b46">Kogut and Zander 1992)</ref>. This literature builds on sociological insights of <ref type="bibr" target="#b89">Ryle (1949)</ref> and <ref type="bibr" target="#b80">Polanyi (1958</ref><ref type="bibr" target="#b81">Polanyi ( , 1966))</ref>, who disentangle the explicit aspects of knowledge from the tacit: aspects of knowledge that are socially embedded, learned through experiences, tied to the senses, and cannot be fully articulated. Accordingly, organi-zational research distinguishes between know-what, or "knowledge as information imply <ref type="bibr">[ing]</ref> what something means" <ref type="bibr">(Kogut and Zander 1992, p. 387)</ref>, and know-how, or "accumulated practical skill or expertise that allows one to do something smoothly and efficiently" <ref type="bibr">(von Hippel 1988, p. 6)</ref>. Scholars studying knowledge in organizations highlight its situated, social, and enacted nature; they depict know-how as "rooted in action, procedures, routines, commitment, ideals, values, and emotions" <ref type="bibr">(Nonaka and von Krogh 2009, p. 636)</ref> and "implicit in our pattern of action and in our feel for the stuff with which we are dealing" <ref type="bibr">(Schön 1983, p. 49)</ref>.</p><p>Experts in a given field are expected to acquire and demonstrate the distinct know-how that internally binds that group <ref type="bibr" target="#b0">(Abbott 1988;</ref><ref type="bibr" target="#b44">Knorr Cetina 1999;</ref><ref type="bibr" target="#b67">Nicolini 2012)</ref>. Accumulated professional practices and protocols that constituted know-how have been documented to be highly difficult to transfer and master <ref type="bibr" target="#b55">(Leonard-Barton 1995;</ref><ref type="bibr" target="#b100">Szulanski 1996)</ref>. Through "learning-by-doing whereby knowledge about how to perform a task accumulates with experience over time" <ref type="bibr">(Garud 1997, p. 84)</ref>, experts come to adopt their field's distinctive know-how, acquiring its unique viewpoint and speaking its language <ref type="bibr" target="#b13">(Brown and Duguid 1991)</ref>. This can create particular difficulty for evaluating a profession's knowhow from the outside, since "the art of one practice tends to be opaque to the practitioners of another" <ref type="bibr">(Schön 1983, p. 271)</ref>.</p><p>When describing the process of professionalization, <ref type="bibr">Abbott (1988, p. 40)</ref> shows how experts work to establish and protect their tacit "professional knowledge system" and hold members accountable for their ability to acquire and demonstrate know-how practices defined by that system (e.g., how to structure problems, evoke rules of relevance, apply abstract inference). Focusing on know-how aspects allows professionals to gain legitimacy and ward off potential occupational challenges seeking to over-simplify the rich know-how practices. <ref type="bibr" target="#b7">Bechky (2003)</ref> showed how engineers in a crossdisciplinary context were able to "maintain their status as experts" (p. 735) since key aspects of engineers' knowledge (their workmanship, tricks of the trade, and tribal knowledge) were not represented in their central knowledge outputs (e.g., technical blueprints and drawings). Instead of being evaluated based on know-what outputs, their professional value hinged on their ability to demonstrate and enact their know-how by using the outputs within larger practices of problem solving and communication.</p><p>Thus, the know-what of knowledge work is difficult to evaluate or even characterize due to the uncertain nature of knowledge in many professional contexts. Instead, more tacit, situated, and social aspects of professionals' knowledge are central to evaluating the quality of the knowledge work. However, today, increasing numbers of AI tools are being designed for and adopted by organizations in knowledge work contexts, raising the important question of how is the quality of these tools being evaluated?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating the Performance of AI Tools</head><p>Generally speaking, evaluating the performance of AI involves assessing its ability to produce the correct output for a given input. The AI tools in this study are image recognition and classification models that use ML-based models to detect and learn patterns between inputs and outputs in prelabeled data sets in order to assign new inputs to predefined output categories <ref type="bibr" target="#b9">(Bechmann and Bowker 2019;</ref><ref type="bibr" target="#b82">Provost and Fawcett 2001)</ref>. These tools are designed using neural networks that are trained to discover probabilistic relationships among features of the input and output data and generate a series of relative weights that can be applied to future data inputs. Measuring the quality of this type of AI model involves calculating how often the model's predicted outputs match the label defined as accurate in the data set reserved for model validation <ref type="bibr" target="#b47">(Kohavi and Provost 1998)</ref>. This calculation is often represented by a metric called the "Area Under the receiver operating Curve," or AUC,<ref type="foot" target="#foot_0">foot_0</ref> and plotted on a twodimensional graph (see example in Appendix B). The AUC summarizes a model's success and error rates, plotting its relative rate of false negatives (excluding an input from the correct class) and false positives (assigning an input to an incorrect class) <ref type="bibr" target="#b83">(Provost and Fawcett 2013)</ref>.</p><p>These output-based performance measures are central to assessing the performance of ML-based AI tools and are frequently cited to indicate the tool's quality. For example, machine learning competitions are typically judged by comparing submitted models' AUC values<ref type="foot" target="#foot_1">foot_1</ref> and measuring them against the baseline performance of human experts in that domain. Researchers and media outlets often report how AI models today are generating lower error rates than humans, claiming, for instance, that "many consider [image classification] solved-the error rate is incredibly low at around 2%" <ref type="bibr" target="#b36">(Gershgorn 2017</ref>). In the context of medical diagnosis, for example, the creators of an AI tool for detecting lung cancer <ref type="bibr" target="#b3">(Ardila et al. 2019)</ref> reported their model's AUC of 0.944 and suggested that this highly accurate model is likely to transform patient care.</p><p>These performance measures are then further amplified (and simplified) as they are cited and incorporated into further academic and economic analyses (e.g., <ref type="bibr" target="#b4">Autor 2015;</ref><ref type="bibr" target="#b24">Dhar 2016;</ref><ref type="bibr" target="#b34">Frey and Osborne 2017;</ref><ref type="bibr" target="#b91">Seamans and Furman 2019;</ref><ref type="bibr" target="#b93">Shoham et al. 2018)</ref>. For instance, researchers predict occupational automation trends by analyzing a prominent dataset (curated by the Electronic Frontier Foundation) that aggregates the highest AUC measures reported for various AI problem domains (e.g., image recognition, speech recognition, language translation) <ref type="bibr" target="#b31">(Felten et al. 2018;</ref><ref type="bibr" target="#b91">Seamans and Furman 2019)</ref>. Similarly, <ref type="bibr" target="#b34">Frey and Osborne (2017)</ref> build on AUC measures published by AI research communities when explaining the assumptions underlying their analysis, including claims that, "today, the problems of navigating a car and decipher handwriting are sufficiently well understood" (p. 259).</p><p>Finally, journalists and media outlets cover these economic and technical reports and further incorporate and simplify the message of AI accuracy measures. These stories often concentrate layered technical arguments and research into attention-catching headlines and brief, flashy conclusions. For instance, a recent New York Times article (Grady 2019) was titled "AI Took a Test to Detect Lung Cancer. It Got an A" and communicated the tool's accuracy in the first sentence: "Computers were as good or better than doctors at detecting tiny lung cancers on CT scans." Nature published an article titled "Rise of Robot Radiologists," which reported the performance of an AI tool as "significantly more accurate at predicting cancer-or the absence of cancer-than practices generally used in clinics" <ref type="bibr">(Reardon 2019, p. S55)</ref>.</p><p>Output-based accuracy measures clearly play a pivotal role in evaluating the performance of modern AI tools and underscore the need for deeper understanding of how these measures are evoked and interpreted in practice. Today, MLbased AI tools are being developed for growing numbers of knowledge work contexts, such as in criminal justice <ref type="bibr" target="#b1">(Angwin et al. 2016;</ref><ref type="bibr" target="#b18">Christin 2014)</ref>, human resource departments <ref type="bibr" target="#b103">(Van Den Broek et al. 2020;</ref><ref type="bibr" target="#b108">Weissmann 2018)</ref>, law enforcement <ref type="bibr" target="#b106">(Waardenburg et al. 2018;</ref><ref type="bibr" target="#b107">Walch 2019)</ref>, and sales departments <ref type="bibr" target="#b74">(Pachidi et al. 2021)</ref>. While some organizational research has begun focusing on how individual experts are perceiving and using AI-generated knowledge outputs in their daily work <ref type="bibr" target="#b45">(Knorr Cetina 2016;</ref><ref type="bibr" target="#b53">Lebovitz 2019;</ref><ref type="bibr" target="#b74">Pachidi et al. 2021)</ref>, we know little about how modern AI tools are being evaluated for potential organizational adoption to begin with. In response to this growing need, this study investigates how managers form evaluations of ML-based AI tools in the context of making medical diagnoses, bringing to light the stifling challenges that arise and the consequences of their evaluation practices for AI adoption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Design and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Setting</head><p>We conducted an 11-month qualitative study investigating how managers formed evaluations of AI tools across multiple sections of a department of diagnostic radiology at a tertiary hospital in the United States (Urbanside). Diagnostic radiology is a medical specialization whereby highly trained physicians use medical imaging technology (e.g., x-ray, CTscan, MRI) to provide diagnostic and treatment recommendations to patients and their team of physicians. The AI tools being evaluated at Urbanside were ML-based classification models based on image recognition technologies; they analyzed medical imaging files as inputs and generated outputs in the form of disease classifications or image segmentation files. Because of the regulatory restrictions in the U.S. at the time of the study, the AI tools were not designed to actively learn or dynamically adapt after implementation. Instead, a "frozen" version of a trained model was submitted for regulatory approval, which could then be deployed into clinical settings. Any model tweaks or improvements required additional rounds of regulatory approval and re-implementation. Details of the five tools analyzed in this study are summarized in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Data Sources. We followed a grounded approach to theory development which involved iteratively analyzing data during and throughout the observational period <ref type="bibr" target="#b17">(Charmaz 2014;</ref><ref type="bibr" target="#b39">Glaser and Strauss 1967)</ref>. The primary data for this study is 11 months of ethnographic observations <ref type="bibr" target="#b104">(Van Maanen 1998)</ref> within Urbanside spanning January to November 2019. Observations focused primarily on how Urbanside managers assessed AI tools for potential adoption in their respective sections (chest imaging, breast imaging, pediatric imaging, and neuroradiology). In all, 23 managers were included in our data collection. In this study, managers refer to boardcertified diagnostic radiology physicians who were actively shaping the assessments of AI in their subsections. Their roles are similar to manager-professional "hybrids" described in prior organizational research <ref type="bibr" target="#b21">(Croft et al. 2015;</ref><ref type="bibr" target="#b57">McGivern et al. 2015)</ref>, as they serve dual roles including both managerial and clinical components. The specific managerprofessional hybrid roles of this study's managers include department chairs, junior and senior diagnostic radiologists formally leading AI research projects or testing AI vendor tools, as well as medically trained AI specialists working on diagnostic AI projects. Most of the managers in this study performed diagnostic radiology work on a daily or weekly </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opensource</head><p>Convolutional neural networks that take two chest X-ray images (from the front and side views) as input and classifies the disease category and the associated result of "normal" or "abnormal." Users can route cases based on the final labels to prioritize the work queue.</p><p>basis (sometimes with a reduced workload) in addition to conducting administrative and AI-related responsibilities. These responsibilities included formally leading and coordinating AI research projects, negotiating with AI vendors, attending and organizing AI conferences and symposia, staying current on published research and regulatory guidelines for diagnostic AI, participating in implementation preparation meetings with hospital IT and infrastructure teams, and so forth.</p><p>Five AI tools are the primary analytical focus since their full evaluation occurred while we had field access. In total, 31 AI evaluation meetings were observed and analyzed, wherein managers spent one to two hours presenting cutting-edge AI tool research, debating tool performance at length with data scientists and other stakeholders, discussing internal pilot studies and implementation plans, and so forth. Observations also include managers participating in industry and research conferences, workshops, symposia, and vendor presentations.</p><p>We conducted 22 semi-structured interviews <ref type="bibr" target="#b96">(Spradley 1979</ref>) and numerous informal conversations with managers supplemented the observational data and deepened our understanding of managers' perceptions of the tools throughout the evaluations. Interviewing the same individuals at different time points helped us understand how their perceptions and opinions about the AI tools shifted over time, what was driving those shifts, and what new discoveries resulted. All interviews were conducted in person in administrative offices and were recorded (with informants' permission and consent) and transcribed.</p><p>Finally, our data collection included archival analysis of over 150 articles detailing diagnostic AI research across the professional and academic literature. We analyzed how these articles reported dimensions of the AI tools, including the diagnostic context, technical infrastructure, training and validation datasets, and reported accuracy measures. Moreover, while observing evaluation meetings and conferences, particular attention was paid to capturing the technical aspects of the tools and how managers engaged with these aspects in practice. The archival data also included AI tools' regulatory filings as well as materials referenced or distributed at academic events, professional workshops, and vendor presentations.</p><p>Data Analysis. The main focus of our analysis was understanding managers' process of evaluating AI tools. In keeping with grounded theory methods, we constantly compared emerging themes and categories across ongoing data collection <ref type="bibr" target="#b17">(Charmaz 2014)</ref>. Early on, we created detailed accounts of managers' evaluation of each AI tool (based on all authors reading the full set of observation, interview, and archival data multiple times) which chronologically captured the range of practices, interactions, and artifacts that were involved. We identified and examined commonalities and differences among the processes for each of the five main AI tools evaluated. We noted, for instance, how managers in all five evaluation processes were highly focused on a tool's AUC measure and the qualifications of the experts producing ground truth labels. We also noted how these became less prominent in the later phases of the process, as they began discovering the disconnects between these measures and experts' practices. Differences in the evaluation processes were mainly observed in how managers adapted the practices to the unique diagnostic context of each AI tool (for example, a measure called the "DICE" score was used for the brain segmentation task, which operated very similar to the AUC measure but was a more appropriate measure for this task). We frequently zoomed in on the specific nature of managers' practices and zoomed out to see how these practices were subject to institutional and organizational forces <ref type="bibr" target="#b66">(Nicolini 2009)</ref>. For instance, we noted managers regularly referred to AUC graphs in their meetings and discussions. Zooming out, we read and analyzed the professional radiology literature and discovered that AUC measures have been used for decades as a core professional method of evaluating diagnostic tools (AI or otherwise).</p><p>Additional analysis focused on understanding the technical nature and differences among the focal diagnostic scenario of each AI tool. We compared the nature of each tool's predictive task as well as how each tool was reportedly trained and validated. This led us to see the similarity in all five tools' underlying technology, whereby all used image recognition and ML-based classification models. We also observed meaningful differences in each tool's diagnostic task and how managers accounted for the specific risks and benefits associated with each distinct diagnosis context. For example, managers in the chest imaging section had different expectations for the AI tool designed to triage urgent patients than managers in the breast imaging department evaluating tools producing specific diagnosis outputs for physicians to consider. This led us to focus more deeply on how managers assessed the reported claims about AI performance within each diagnostic context and how they weighed the relative risks and benefits of each tool.</p><p>We analyzed relationships between themes across the five tools (Golden-Biddle and Locke 2007), noting similarity in patterns. For instance, across all five evaluation processes, managers' focus shifted from one measure to the next in similar phases, from analyzing AUC measures to eventually turning their focus inward to analyze the practices of experts in their field. Analyzing these shifts in managers' focus and practices led us to notice how certain aspects of the tools were scrutinized (or ignored) as the tool evaluation unfolded over time. For example, specific aspects of research articles and vendor materials were central early on, whereas other aspects like the internal pilot study results and internally produced ground truth labels gained prominence later in their evaluations. A key insight from this analysis was observing how, in all five evaluation processes, managers' focus ultimately shifted inward, to scrutinizing the uncertainty and variability of the performance of experts in their field and the lack of reliable measures of quality in many scenarios. We engaged with literatures on the uncertain nature of knowledge work, evaluation of new technologies, and the specific ways AI tools are evaluated. Iterating with our emerging concepts involved in managers' AI evaluation process, we focused even more specifically on literatures related to how knowledge is evaluated in professional contexts (and the importance of both know-what and know-how aspects of knowledge) compared to how it is evaluated in ML-based AI development communities (based on knowledge outputs). As we integrated and adapted concepts of know-how and know-what to the quality measures managers were evaluating, we were able to better conceptualize and theorize their AI evaluation process and its implications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Focusing on Reported Claims of the High Quality of AI Tools</head><p>Underlying the rise of the new generation of ML-based AI tools were appealing promises of relieving human workloads without compromising quality. Urbanside managers, like managers in many organizations, were grappling with the competing demands of coping with high work volumes while providing high-quality services: "This is our constant struggle: the 'bottom line' [increasing revenues and decreasing costs] versus the fact that we are here trying our best to do our job for our patients" (Irene </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assessing the Reported AUC Accuracy Measures of AI Tools</head><p>Assessing the reported accuracy measures of AI tools was critical to forming managers' opinions about the quality of the AI tools: "If there's a well-designed study that proves that the tool's accurate, I'd be comfortable with that" (Miguel). Measures reported in published studies were crucial, and managers specifically focused on reported AUC measures to assess tool quality. The AUC is an aggregated measure ranging from zero to one, that represents the accuracy of the model across different configurations; it summarizes how well the model's predicted outputs match the outputs predefined in the test data set by the developers. Professionals in the field of diagnostic radiology are trained to focus on AUC measures when judging whether any technological tool (far before and beyond AI) improves diagnostic accuracy (see example in Appendix B), from assessing the quality of imaging equipment (e.g., x-ray or MRI) to analytical tools built into imaging software (e.g., Tensor Flow Analysis, tomosynthesis). So, Urbanside managers readily focused on AUC measures for diagnostic AI tools and searched for tools "pushing that [AUC] curve into the upper left corner" (Vivian), that is, nearing the optimal score of 1.0. Tools approaching 1.0 were expected to consistently generate near-perfect diagnoses in practice (zero false positive and false negative errors).</p><p>AUC measures were reported prominently in the AI materials managers were consulting, including research publications, vendor documentation, regulatory applications, and patent filings. Very often, such materials reported AUC values as the primary evidence of performance, such as in medical journal abstracts that were open for free to the public (see example in Figure <ref type="figure" target="#fig_0">1</ref>) and when vendor presentations dramatically revealed AUC values. Typically, a tool's AUC measure was reported in comparison to another method, usually expert radiologists or a competing tool, to suggest the tool's ability to improve diagnosis accuracy (see Appendix C).</p><p>Thus, managers regarded AUC measures as a short-hand indicator of the quality of an AI tool's outputs and error rates relative to experts', as Cyrus explained: "When we're talking about performance, it comes down to what is the accuracy of the method? It comes down to looking at the AUC number … At what point is the tool better than what we would do on our own?" Managers used the AUC measure to compare the AI outputs to experts' outputs when evaluating the Breast Mammo Tool, "The deep learning model is better than humans in terms of the common metrics used, in terms of AUC" (Chris), and the Bone Age tool, "The tool's performance was shown to be as good as, or slightly better than, radiologists' interpretations" (Nadia). Managers also used AUC measures to weigh relative costs of errors within a given diagnostic context and grasp the tool's potential risks and benefits: "Would you rather have a model that … found all the abnormal diseases, but had a lot of false positives that the radiologist had to go through? Or one that is particularly specific but might miss something?" (Sadie).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shifting Focus to the "Ground Truth" Used to Train and Validate ML-Based AI Tools</head><p>While assessing a tool's AUC measures, managers also began investigating the source of the "ground truth" created by the AI developers. Here, the term ground truth refers to the labels assigned to the data sets used to train a ML model to link new inputs to outputs and to validate its performance. Many diagnostic ML models relied on the diagnosis decisions of licensed radiologists as the ground truth labels, which was considered good practice for AI developers in this field, as illustrated by materials published by the Chest Triage tool creators: "Ground truth is critical in evaluating deep learning models in medical imaging and provide the foundation for clinical relevance when interpreting results in this field-this is why we focus a lot of our effort on considering the best available ground truth via a panel of medical sub-specialist experts."</p><p>Managers recognized that ground truth labels were integral to measuring ML-based AI performance, as they served as the baseline outputs to compare against the model's outputs.</p><p>Higher skepticism was expressed towards a model that used diagnosis opinions provided by novices versus seasoned experts. This was illustrated by managers assessing the Bone Age tool, who were frustrated by the lack of visibility into the source of the model's ground truth labels, "If I knew the data was all labeled by pediatric radiologists who had read thousands and thousands of bone ages, I think I would consider [the model] to be probably more vetted, more trustworthy than if it had just been fed college students' reads who were just taught how to read them" (Nadia).</p><p>Managers searched for indicators of the caliber of the humans producing the ground truth labels. Indicators like the quantity, qualifications, and years of experience of the individuals labeling the data often appeared in published documentation and the limited summary section of research articles (see Figure <ref type="figure" target="#fig_0">1</ref>). This was the case for the Brain Tumor Segmentation tool documentation describing how four physicians followed the same protocol to generate the data labels, which were then refined and approved by a certified neuroradiologist. These details were also uncovered in published regulatory filings, where managers found a detailed table</p><p>summarizing who provided ground truth labels for the Breast Ultrasound tool (see Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Focusing on Conducting and Assessing Internal Pilot Studies</head><p>Satisfied with the reported performance claims for five AI tools, managers turned their focus towards evaluating them within their local work environment. In the case of the Bone Age tool, managers were eager to conduct pilot studies since the tool had previously "only been tested in the hospital where it was developed. How do we know if it will be applicable and function here? … We need to know: does the model generalize to our setting?" (Nadia). Assessing the tool's internal performance was critical before moving towards full implementation, as Savannah from the breast imaging department explained, "If the [Breast Ultrasound tool] study shows positive results, that means we [breast imaging radiologists] are going to be more productive, which is what we want. But we don't want to waste everyone's time before we know for sure."</p><p>Importantly, managers had to carefully define what internal measures of quality they would use to assess each tool's performance. In all five cases, managers hand-selected Urbanside experts to produce the ground truth diagnosis labels for each study. For the Bone Age tool, two senior radiologists recorded independent decisions, and the average of the two was recorded as the ground truth for each case.</p><p>Then, AUC measures were generated to assess how well the AI outputs matched the opinions recorded by the experts. For the Chest Triage tool, the consensus of two chest radiologists' independent assessments was also used as the ground truth.</p><p>In this case, managers also decided to adjust the label of one disease, cardiomegaly, from "abnormal" to "normal," which adjusted the volume of cases ultimately elevated to their prioritized worklist.</p><p>Managers debated the specifics of the ground truth labels they would use for the Brain Tumor Segmentation tool: "Is there intra-observer variability? If I do one, and you do one, if he does one, are we happy with that? Or does it then have to go through one person to check them all?" (Vivian). They ultimately decided to compare the tool's outputs to segmentation labels generated by a senior neuroradiologist. Finally, for both the Breast Mammo and Breast Ultrasound tools, managers decided to follow a common standard used in published AI studies: one radiologist's judgment would serve as the ground truth for the majority of cases, complemented by a three-month follow-up assessment or pathology findings when available.</p><p>As each study concluded, managers were quite surprised by the internal results, as many results conflicted with the accuracy measures reported by tool developers. For instance, when segmentation results of the Brain Tumor Segmentation tool were projected on the screen against the ground truth label, managers gazed at them in disbelief, "The segmentation is atrocious! It takes half the scalp with it. That makes no sense … Not only is it highlighting stuff in the brain that is totally irrelevant, but it doesn't actually highlight the important parts of the tumor!" (Vivian). Desperate to understand these conflicting results, managers searched for explanations, "The results were far more discrepant than I expected, and I don't know why" <ref type="bibr">(Anthony)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How the Focus Shifted to Comparing Experts' Process to AI Processes</head><p>To investigate the underwhelming internal performance of the AI tools, managers began comparing experts' diagnosis approach to how the ML model determined its outputs.</p><p>Unpacking the Bone Age tool's poor performance led managers to question whether the ML model was "taught" to use different standards than internal experts' professional training: "Is it possible that our internal standards are slightly different [than those used by the developers]? Or that we've been taught [to generate diagnoses] differently than the algorithm was taught?" <ref type="bibr">(Anthony)</ref>.</p><p>Managers focused on comparing the evidence represented in the data used to train the AI models to the evidence experts used to form diagnosis opinions. Doing so led managers to confront the limitations of models' training data in that only a narrow subset of the relevant diagnosis inputs was captured in the datasets underlying the ML model. In the case of the Breast Ultrasound tool, managers questioned the validity of a model whose outputs were based solely on two cropped ultrasound images, including Savannah remarking, "The software does not take into account certain clinical variables which are so very important," and Lola commenting, "There's a lot of art of [patient's case] management that's not accounted for by the tool."</p><p>Moreover, managers began scrutinizing how ground truth labels were defined and generated, extending their earlier focus on assessing who generated the labels. For the Breast Mammo tool, significant discrepancies were discovered between how the labelers generated the ground truth and experts' approach in their daily practice: "The readers were not looking at prior images. It was done intentionally, to keep it, you know, apples-to-apples, a controlled way to do the study. But it's not even close to real practice" (Lola).</p><p>Looking at prior images was an essential and fundamental analytical practice for radiologists; not doing so is considered a genuine act of malpractice in the field. Urbanside managers uncovered that experts labeling ground truth cases were only analyzing the current image, driven by developers' desire to draw an "apples-to-apples" comparison between the AI and human outputs. This new realization led managers to confront the limitations of using such measures to evaluate AI tools and increased their skepticism about the tools' reported performance claims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Unexpected Consequence of Evaluating AI Performance</head><p>Managers continued to dig deeper into how ground truth labels were constructed and ultimately confronted even deeper limitations of using human-generated labels: the deep uncertainty human experts face when generating diagnosis outputs. Managers struggled to reconcile the practice of using expertgenerated labels as the ground truth when, in practice, these opinions lacked strong external validation, as explained by Sadie, "All we have for the ground truth is the radiologists … That doesn't necessarily mean that is the right answer, but it's what we have now," and Leslie, "There's no gold standard. The standard we use is the radiologists' read, but is the radiologist right? We don't know!"</p><p>Providing medical diagnoses is ambiguous and uncertain knowledge work, plagued with a lack of agreement about what constitutes an absolute or "accurate" opinion. After a radiologist diagnoses a patient, it is difficult to know for certain the accuracy of that diagnosis. <ref type="foot" target="#foot_3">5</ref> In practice, it was common for radiologists to form conflicting conclusions about a particular diagnosis, even when highly trained experts were presented with the same full set of medical information (e.g., De <ref type="bibr" target="#b22">Sanctis et al. 2014;</ref><ref type="bibr" target="#b27">Duijm et al. 2009;</ref><ref type="bibr" target="#b52">Lazarus et al. 2006)</ref>. Diagnostic errors are a major area of research in this professional field, reporting how such errors impact between 10 and 20 percent of cases, as many as one in five patients overall <ref type="bibr" target="#b11">(Berner and Graber 2008;</ref><ref type="bibr" target="#b15">Bruno et al. 2015)</ref>. As one Urbanside manager explained solemnly, "We all have misses. Interpretation is hard. It's not necessarily like you weren't looking or paying attention. It's like, you interpreted it, right? And we can be right or wrong when we interpret things" (Leslie).</p><p>Acknowledging these limitations, some measures of performance in the diagnostic radiology field are considered more or less reliable for determining the accuracy of a given judgment. Professional standards based on clinical outcomes, such as pathology reports and/or long-term follow-up records, for instance, are considered high quality measures of performance for breast cancer diagnosis because they represent the current best possible evidence to confirm the diagnosis. However, in many diagnostic scenarios (where standards are difficult to obtain in terms of time, cost, technology resources, and patient privacy concerns), the field recommends that one or multiple experts' diagnostic assessments may serve as a measure of diagnosis quality. <ref type="foot" target="#foot_4">6</ref> This was the scenario that managers faced when evaluating both of the AI tools for breast cancer diagnosis, where the professional standard (as well as the expected level of evidence required by most medical journals) would require pathology reports or long-term follow-up records. However, ML research commonly uses experts' diagnoses as the standard, and managers expressed discomfort drawing firm conclusions on that basis, given the high uncertainty and variability of experts' opinions: "The outcomes in breast cancer, by definition, need to be long-term outcomes. So, if some results are false negatives, you need at least a year to figure out if they were wrong … How valid are these results if they are not incorporating the long-term outcomes?" (Savannah).</p><p>In all five cases of AI tool evaluation, managers faced the crippling limitations of using expert-generated ground truth labels to evaluate ML-based AI tools. When unpacking the poor results of the Brain Tumor Segmentation tool pilot, managers began scrutinizing the ground truth labels they constructed internally: "How good is our standard for segmenting brain tumors? Let's take a look at what the heck was segmented and see how good is it?" (Vivian). Projecting one of the labels on the screen prompted concerned comments about its quality, "In the center, the core, there are some really patchy areas … It's very important we get that [label] right. We can't move forward with anything until we have a gold standard, something to measure the tool against" (Yanis). An extensive debate followed: they described in detail highly varied approaches to how they would have labeled the tumor's regions in practice. Multiple tumor segmenting standards were available in the neuroradiology field, each yielding different outputs. Thus, determining ground truth labels defining the brain tumor's edges was subject to deep underlying ambiguity: "According to our standard protocol for this task, that label is considered acceptable. But I think, maybe, that just isn't a good standard, in general" (Vivian).</p><p>Similarly, managers sought to understand why the Bone Age tool's outputs frequently diverged from the ground truth labels experts had generated internally. Managers began discussing the high variability between and within even highly trained experts at Urbanside and the field's lack of external methods to validate bone age diagnoses. Confronting the underlying uncertainty about the quality of human experts' knowledge led managers to question their ability to use expert-generated diagnoses to evaluate the accuracy of AI outputs: "I feel like my opinions might be different than other people's opinions. I also don't know how good the intra-observer rate is. And also, the inter-observer. I have no idea how good we [experts] are. So, is using our opinions a good way to train and test the machine? I don't know" (Nadia).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcomes of Evaluating AI Tools</head><p>In the end, managers' AI evaluation process, which is summarized in Table <ref type="table" target="#tab_3">2</ref>, resulted in three of the five piloted AI tools moving forward towards deeper exploration in the hospital, while the future for two tools was less clear. For the latter, the Breast Mammo and Breast Ultrasound tools, managers recognized the limitations of using ground truth measures based on experts' diagnoses and struggled to evaluate each tool's performance in a satisfying way: "There were a lot of situations where the model was wrong. There were also a lot of situations where the radiologist was wrong.</p><p>There was a lot of discordant information" (Stella regarding the Breast Mammo tool). They considered the relative risks of using the tools, from the potential errors it may introduce to the potential increases in costs, as in the case of the Breast Ultrasound tool pilot suggesting slower diagnosis speeds, "For each lesion, you need to draw a little box into two different planes of view, so there's additional time for that extra maneuvering" (Savannah). These additional risks could not be justified since it was not clear what (if any) benefits the tool may generate if implemented.</p><p>In contrast, three AI tools were on a path of deeper exploration and potential implementation at Urbanside. Despite lacking a clear assessment of a tool's accuracy (given the underlying uncertainty of expert outputs), managers' AI evaluation process enabled them to have a clearer sense of a tool's relative risks and benefits. For the Bone Age and Brain Tumor Segmentation tools, managers were motivated by the underlying uncertainty and lack of established professional standards for the focal tasks. They viewed implementing these tools as a way to more deeply explore and potentially improve these diagnosis methods, which they viewed as outweighing the risk of the tool generating flawed outputs: "Even if the tool has some degree of error in it, it is still better than [our current method] for measuring the tumors-which is horrible! So almost anything would be an improvement" (Vivian). Furthermore, while the pilots did not analyze diagnosis speeds, managers were hopeful that the tools may increase efficiency, "It makes radiologists' lives easier. It shortens the times for us to measure the tumor" (Alvin).</p><p>Finally, managers decided that the benefits of moving forward with the Chest Triage tool outweighed its potential risks: "[The department chair] has already given his stamp of approval. I think as long as it's efficient, there's no questioning it." In this context, managers were notably more tolerant of potential AI errors. They were using the tool to "massively decrease turn-around-times" (Bob) for urgent cases, while still applying experts' full range of practices to make diagnosis decisions: "I'm okay with the model being wrong sometimes [overclassifying cases as urgent], as long as we don't miss [truly urgent] cases" (Leslie). Managers were ultimately driven by the promise that the AI tool may greatly improve patients' lives: "Getting to acute patients faster could impact their care and their health and their feelings and avoid possible complications. Isn't that the point of medicine? That's what [the tool] is doing" (Leslie).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this study, we unpack the process of evaluating ML-based AI tools in a context of professional knowledge work (medical diagnosis). Initially, managers focused on specific reports of high AI tool accuracy and assessed AUC measures and expert-generated ground truth labels published by tool creators. Managers chose five tools for further evaluation and conducted pilot studies to assess how well the AI outputs compared to internal experts' outputs. However, the pilots yielded disappointing results and left managers searching for explanations. As managers dug deeper, it brought them to confront the underlying challenge of evaluating the performance of human experts, as many diagnostic scenarios lack strong validation of the diagnosis outcome. As in many knowledge-intensive contexts, experts developed over the years rich know-how practices to form high-quality knowledge outputs. Thus, to evaluate AI outputs, managers began reflecting on the know-how practices that enable internal experts to grapple with uncertainty in their daily work and produce high-quality judgments. As a result, managers came  • Demonstrating mastery of practices and problem-solving approaches guided by the knowledge system of a given professional field. • Acceptance that one may never achieve full certainty in practice given limits of many knowledge contexts, but that relying on and applying know-how enables acceptable levels of certainty in practice.</p><p>to recognize a troubling disconnect between ML-based AI quality measures that were based solely on know-what aspects of knowledge and the rich know-how practices experts rely on in their daily work. These realizations had profound implications for managers' AI evaluations and their assessment of each tool's potential risks and benefits.</p><p>A key insight of this study is uncovering the limitations of using know-what-based measures that ignore experts' knowhow in evaluating ML-based AI tools for knowledge work. Table <ref type="table" target="#tab_4">3</ref> summarizes our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quality measures based on know-what.</head><p>Ground truth labels used for training and evaluating AI tools, professional standards of diagnostic output quality, and aggregated AI performance accuracy were critical to managers' AI evaluation process but eventually proved problematic due to their emphasis on know-what aspects of knowledge. Regarding ground truth measures, AI creators select ground truth labels that attempt to represent the "accurate" knowledge output for every input in training datasets. In this study, managers initially scrutinized the qualifications of the labelers and treated ground truth labels as taken-for-granted representations of knowledge in their field. Eventually, they recognized how even labels generated by experts limited their evaluations since experts' knowledge outputs were subject to deep underlying uncertainty and ignored know-how aspects of knowledge that were essential to producing knowledge in practice.</p><p>The second quality measure based on know-what is a professional standard of diagnostic output quality. These measures are set in the context of a professional field and have strong reputations for being the most accurate or best available benchmark to establish the accuracy of knowledge outputs.</p><p>In medical diagnosis, for example, a professional standard for the accuracy of a diagnosis is often established using longterm patient outcomes or microscopic evidence. Managers faced the limits of professional standards of diagnostic quality for all five tools in this study. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical and Practical Implications</head><p>AI tools are rapidly emerging in many professional knowledge contexts using expert-provided labels as the ground truth <ref type="bibr" target="#b61">(Mitchell et al. 1990;</ref><ref type="bibr" target="#b95">Smyth et al. 1994</ref>), yet the highly uncertain nature of experts' knowledge outputs is going largely unexamined. By identifying how ML-based AI tool evaluation focuses on know-what measures, while professional knowledge work focuses on know-how measures, we offer a number of theoretical implications and future research directions, which are examined in the following section and summarized in Table <ref type="table" target="#tab_6">4</ref>.</p><p>This study highlights the vital importance of conducting thorough evaluations of AI tools for contexts of expert knowledge work. Only through a deep process of unpacking the AI tools were managers able to understand AI performance levels and appreciate the potential risks and opportunities of adopting each specific tool. At the same time, recently, innovation in many fields has been accelerated <ref type="bibr" target="#b56">(Lifshitz-Assaf et al. 2021)</ref>. This became evident in the global pandemic when there was "gold rush" to AI for helping address COVID-19 <ref type="bibr" target="#b38">(Gkeredakis et al. 2021)</ref>. Our study's findings warn against the rushed adoption of AI tools, particularly for new problems wherein the underlying knowledge is uncertain or immature. The diligence of the evaluation process conducted by managers in our study exposed the gaps between the know-what of ML-based AI tools and experts' know-how. However, in many settings, AI is adopted without such diligent evaluation, and it might take a long time for the resulting damage to be captured. For instance, AI was adopted very rapidly for COVID-19 patient-related care decisions, including treatment choices and patient dismissal decisions. How could these systems be trained properly according to expert's standards? For instance, were ML models trained on data that included tracking of dismissed patients' clinical outcomes? Would there be a way for these ML models to learn if patients were erroneously discharged? Recently, ML researchers themselves started raised such concerns, finding serious flaws with many algorithms developed in the early stages of the pandemic <ref type="bibr" target="#b88">(Roberts et al. 2021)</ref>.</p><p>A diligent evaluation of such tools could have surfaced such flaws. As some professional fields begin taking steps to formalize how AI ought to be evaluated (e.g., <ref type="bibr" target="#b63">Mongan et al. 2020)</ref>, our study speaks directly to what diligent evaluations should encompass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Tension Between Evaluating AI and Evaluating Experts</head><p>This study illuminates the strong tension between how MLbased AI tools are evaluated (using quality measures of knowwhat) and how experts evaluate their work (based on knowhow). It is critical to examine and understand the limitations of any measures based on know-what aspects of knowledge (e.g., ground truth measures and AUC measures) that ignore the know-how. Prior literature describes how know-what and know-how aspects of knowledge are inherently inseparable <ref type="bibr" target="#b81">(Polanyi 1966;</ref><ref type="bibr" target="#b89">Ryle 1949)</ref>, in that all knowing emerges from and is rooted in situated practices <ref type="bibr">(Brown and</ref><ref type="bibr">Duguid 1991, 2001;</ref><ref type="bibr" target="#b51">Lave 1988;</ref><ref type="bibr" target="#b72">Orlikowski 2002)</ref>. Measures using knowwhat as the sole representation of knowledge are therefore inherently incomplete. In constructing ground truth labels and AUC measures based on know-what knowledge outputs, ML model developers divorce "a view of knowledge as a separate entity, static property, or stable disposition embedded in practice, [from] a view of knowledge as … enacted-every day and over time-in people's practices" <ref type="bibr">(Orlikowski 2002, p. 250)</ref>. And yet, despite that know-what measures ignore how "knowing is in our action" <ref type="bibr">(Schön 1983, p. 49)</ref>, they have become a prominent, taken-for-granted means of evaluating ML-based AI tools. • When do tacit and contextual aspects of experts' knowhow lead to greater know-what performance? • How can ML tools be developed to take into account more of experts' know-how, and would this impact the performance of ML tools in practice? • Will the adoption of ML tools that replace human experts lead to knowledge stagnation in a professional field due to the erosion of know-how knowledge? • How can "explainable AI" be used to compare machine classification processes with experts' know-how? How can this comparison be used to improve both ML-based AI tool performance and human know-how knowledge?</p><p>Currently, ML-based AI creators do not account for these limitations of know-what-based measures when reporting and advertising the performance of tools. Since the days of expert systems, computer science researchers have attempted to capture and codify experts' knowledge <ref type="bibr" target="#b26">(Dreyfus et al. 2000;</ref><ref type="bibr" target="#b33">Forsythe 1993;</ref><ref type="bibr" target="#b94">Simon 1987</ref>) and experienced difficulties of faithfully representing tacit know-how in technological form (e.g., <ref type="bibr" target="#b43">Hutchins 1995;</ref><ref type="bibr" target="#b71">Orlikowski 1992;</ref><ref type="bibr" target="#b97">Star 1989;</ref><ref type="bibr" target="#b99">Suchman 1987)</ref>. Today, however, there is renewed hope that ML-based AI can bypass capturing tacit elements of experts' process by implicitly learning the patterns linking inputs to outputs. This assumes that what is being linked-the ground truth datasets defining the input and output-reliably represent knowledge in that domain. Issues are known to arise when constructing ground truth measures for ML models in contexts where knowledge claims are unreliable <ref type="bibr" target="#b92">(Sheng et al. 2008)</ref>, such as when outputs are disputed, subject to multiple interpretations, or even unavailable. While some researchers are actively developing benchmarks and methods for improving ground truth acquisition in ML research <ref type="bibr" target="#b48">(Krig 2016;</ref><ref type="bibr" target="#b60">Milan et al. 2013)</ref>, the majority of ML researchers avoid the problem altogether by selecting domains with less disputed outcomes, such as images of physical objects (e.g., <ref type="bibr" target="#b23">Deng et al. 2009)</ref> or audio-signals <ref type="bibr" target="#b62">(Mohamed et al. 2012)</ref>.</p><p>In contrast to AI tool creators ignoring the limitations of know-what, members of professional fields widely acknowledge these limitations in their everyday practice and focus on exercising their know-how. Over decades, experts cultivate rich practices to build practically acceptable levels of certainty in their everyday work <ref type="bibr" target="#b44">(Knorr Cetina 1999)</ref>. Many professional fields hold their members accountable for their ability to adhere to this "professional knowledge system" <ref type="bibr" target="#b0">(Abbott 1988</ref>) rather than enforcing a standard based solely on know-what outcomes. For instance, when radiologists are sued for a diagnostic error, they avoid malpractice charges by showing they adhered to their professional process standards, following all of the best available practices and protocols according to their know-how. Professionals must trust that their know-how will help them avoid negative outcomes, or else the uncertainty they face in their know-what may be paralyzing.</p><p>Our study also relates to the growing discourse and body of research focusing on "explainable AI" (e.g., <ref type="bibr" target="#b5">Barredo Arrieta et al. 2020;</ref><ref type="bibr" target="#b6">Bauer et al. 2021;</ref><ref type="bibr" target="#b32">Fernández-Loría et al. 2020;</ref><ref type="bibr" target="#b42">Guidotti et al. 2018)</ref>. Managers in this study were actively searching for ways to better understand the "black box" of the AI tools during their evaluations. Indeed, one of the key drivers behind the movement towards explainable AI research is the eagerness of managers performing AI evaluation to understand how the tools were developed and what processes they use to derive outputs. Unpacking such processes can help managers compare AI processes with experts' knowhow. Such comparison may create an opportunity for learning, where it can reveal if a crucial part of know-how is not captured by the machine; vice-versa, it may enable human experts to learn from the AI processes. Moreover, if explainable AI for ML-based tools reveals inconsistencies in how machines classify similar input data (e.g., using different parts of the image every time a classification is done), this may prompt managers to question the reliability of such AI tools. Explainable AI, however, would not be able to address critical challenges that we have identified in this study associated with the limitations of the ground truth labels and the lack of uniform professional standards that characterize many areas of professional knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Risky Consequences of Treating Constructed Quality Measures Objectively</head><p>Our study highlights the constructed nature of the measures commonly used to evaluate ML-based AI tools and the consequences of treating them as objective means of judging knowledge. Ground truth labels and AUC measures were often presented in quantified forms, which are known to increase the appearance of objectivity while hiding the situated, embodied, and equivocal nature of the underlying knowledge being represented <ref type="bibr" target="#b9">(Bechmann and Bowker 2019;</ref><ref type="bibr" target="#b28">Espeland and Stevens 2008;</ref><ref type="bibr" target="#b77">Pentland 1993</ref>). However, despite the popularity of the term "ground truth," prior scholars have argued that such measures are far from objective or neutral, but are socially constructed and subject to ongoing debate and contestation <ref type="bibr" target="#b12">(Bowker and Star 2000;</ref><ref type="bibr" target="#b37">Gitelman 2013;</ref><ref type="bibr" target="#b50">Latour 1987;</ref><ref type="bibr" target="#b102">Timmermans and Berg 2003)</ref>.</p><p>In particular, prior literature examining the constructed nature of categories and labels in (digital and nondigital) classification systems has emphasized the high degree of subjectivity, abstraction, and influence underlying decisions to form and define labels <ref type="bibr" target="#b8">(Bechky 2021;</ref><ref type="bibr" target="#b12">Bowker and Star 2000)</ref>.</p><p>Recently, research has begun investigating the influential role of ML-based AI tool creators in constructing ground truth labels and arbitrating the "right" knowledge that AI tools should generate <ref type="bibr" target="#b9">(Bechmann and Bowker 2019;</ref><ref type="bibr" target="#b76">Pasquale 2015)</ref>. Further research is needed, however, to better understand how constructed ground truth labels shape the performance of ML-based AI tools and impact their adoption and use in organizational contexts.</p><p>Our study illuminates how ground truth measures were treated objectively, despite their constructed nature. Prior literature describes how knowledge that is removed from situated work processes begins to take on a more objective and static quality <ref type="bibr" target="#b10">(Berger and Luckmann 1966;</ref><ref type="bibr" target="#b50">Latour 1987</ref>) that may then be represented in and associated with technological artifacts <ref type="bibr" target="#b78">(Pentland 1995)</ref>. Part of the process of forming judgments about new technologies has been shown to involve individuals questioning the measures, artifacts, and quantifications meant to represent knowledge in a given field <ref type="bibr" target="#b2">(Anthony 2018;</ref><ref type="bibr" target="#b28">Espeland and Stevens 2008;</ref><ref type="bibr" target="#b77">Pentland 1993)</ref>. Attending to these issues involves actively unfolding and scrutinizing the technology and its related artifacts, "unraveling of the features of physical and technical objects, of their details, composition, hidden sequences, and behavioral implications" <ref type="bibr">(Knorr Cetina 1999, pp. 71-72)</ref>.</p><p>In our study, the spell of objectivity surrounding AI measures that are based on know-what was broken when managers began comparing these measures to experts' rich professional know-how and recognizing the serious disconnect. Focusing on a specific ground truth label (previously assumed to represent the "accurate" diagnosis), they recontextualized it within its situated problem scenario and analyzed the diagnosis as an expert would in their daily practice. After discussing and debating the patient's specific condition, potential imaging nuances, and conflicting evidence of disease progressions, they concluded that multiple diagnoses were equally likely and recording any one as the "ground truth" was unacceptable. In other words, as managers drew on experts' rich and multifaceted know-how practices, they reconsidered the validity of ground truth labels based solely on experts' knowwhat knowledge outputs.</p><p>Understanding the constructed nature of AI performance claims is not only useful for managers evaluating AI tools; it is also critical for anyone engaging with or referencing quality measures of know-what for academic or policy-related purposes. Our study points to the risks of taking-for-granted measures based on know-what and ignoring their limitations when incorporating them into aggregated studies and performance claims. Take, for instance, ImageNet models' high AUC measures <ref type="bibr" target="#b36">(Gershgorn 2017;</ref><ref type="bibr" target="#b75">Parloff 2016</ref>) which are commonly cited as clear evidence of AI's strengths and abilities to support analyses of employment and automation trends (e.g., Dhar 2016; Frey and Osborne 2017; Seamans and Furman 2019). Our findings would urge for explicitness about the constructed nature of the measures underlying ImageNet performance claims and the limitations of being built upon popular datasets using crowdsourced image labeling as the ground truth. Explicitness about possible risks and limitations is critical, since, as this study showed, these claims often serve as the driving force behind the adoption of highly consequential AI tools at growing scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relying on AI Outputs May Severely Limit Learning</head><p>Finally, if ML-based AI tools are indeed implemented at scale in knowledge-intensive contexts, the dilemmas that surfaced in this study would be further exacerbated and lead to major consequences. Namely, organizational and professional learning processes may disappear if know-what-based AI outputs dominate decision-making contexts and erode experts' tacit know-how. Once AI tools are perceived as taken-forgranted and objective <ref type="bibr" target="#b10">(Berger and Luckmann 1966;</ref><ref type="bibr" target="#b50">Latour 1987)</ref>, and experts rely on seemingly accurate AI outputs as a welcome reprieve from their uncertainty, fundamental organizational changes may follow. Moving forward, AI tools and their trusted outputs may influence the social and technological ensemble that generates the very data on which the tool is trained <ref type="bibr" target="#b29">(Faraj et al. 2018;</ref><ref type="bibr" target="#b73">Orlikowski and Scott 2014;</ref><ref type="bibr" target="#b74">Pachidi et al. 2021)</ref>. For instance, in a recent study, <ref type="bibr" target="#b74">Pachidi et al. (2021)</ref> find that sales professionals responded to a new tool by continuing to work according to their expert know-how and used the tool in symbolic ways only. However, their perfunctory use generated new data which further trained and legitimized the predictive model, and, ironically, resulted in the entire sales staff being laid off.</p><p>In the future, a "new know-how," which is augmented and influenced by AI outputs, may eventually represent the sole remaining source of knowledge in an organization and stunt the possibility for learning (in addition to improving the tool).</p><p>Organizational researchers have theorized about the dynamic way of knowing transforms through humans "interacting, discovering 'truth,' justifying observations, defining problems, and solving them," which fuels how "knowledge alternates between tacit knowledge that may give rise to new explicit knowledge and vice versa … Tacit and explicit knowledge mutually enhance each other towards increasing the capacity to act" <ref type="bibr">(Nonaka and von Krogh 2009, p. 638</ref>). This process is likely to dissolve if AI tools' explicit outputs overshadow the tacit aspects of experts' knowledge processes and know-how <ref type="bibr" target="#b30">(Feldman 2004</ref>). If, however, both humans and AI tools operate in parallel, both retain the potential to learn and evolve, and there is the important potential to continue observing and scrutinizing the performance of both over time. However, operating in parallel is highly difficult and expensive in practice, especially as organizational leaders urge AI tool adoption based on promised efficiency gains.</p><p>Based on this study, we suggest two possible ways of addressing these concerns. In areas where scientific knowledge is highly uncertain, human experts must remain the final arbiter of decision-making in practice. For fields with more established knowledge claims, based on our study, we recommend that AI tools should be trained and validated on quality measures that more closely resemble know-how and experts' practically acceptable performance.</p><p>Ever since the Turing Test, the performance of computers has been measured in head-to-head comparisons with the performance of humans. Today, the sentiment has not changed, and comparisons are routinely drawn between AI tools and human experts in growing numbers of domains. Moreover, today AI tools are being developed for increasingly more critical individual, organizational, and societal decisions. Such decisions, however, are often embedded in contexts where human experts routinely experience uncertainty-producing judgments and, as a result, rely on their know-how to address limitations of their know-what. In such contexts, organizational actors should be cautious in developing and adopting AI tools that are based on human experts' know-what knowledge. Such tools may not only produce poor decisions that are consequential but may also limit our ability to learn how to improve such decisions in the future. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Details of Accuracy Measures and Select Model Details Included in the First Page Summary of an AI Research Article Published in Radiology: Artificial Intelligence (E. F. Conant, A. Y. Toledano, J. W. Hoffmeister, et al., "Improving Accuracy and Efficiency with Concurrent Use of Artificial Intelligence for Digital Breast Tomosynthesis," Radiology: Artificial Intelligence, 2019. © Radiological Society of North America)</figDesc><graphic url="image-2.png" coords="9,140,46,85,92,331,20,247,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure C2 .</head><label>C2</label><figDesc>Figure C2. FDA Filing for Breast Ultrasound Tool Showing Details of Physicians Involved in the Tool's Validation Study</figDesc><graphic url="image-7.png" coords="25,175,86,328,20,266,40,97,26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-3.png" coords="23,75,54,120,42,460,86,264,42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-5.png" coords="24,189,00,442,68,234,06,230,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Comparing Five AI Tools Being Evaluated at Urbanside Tool Name Urbanside subsection of Radiology Department Nature of the Tool's Diagnostic Task Measure of the Performance of the Diagnosis Task Tool Source Tool Design</head><label>1</label><figDesc></figDesc><table><row><cell>Brain Tumor</cell><cell>• Generate segmentation labels for</cell><cell>• No absolute measure of</cell><cell>Open</cell><cell>Cascade of convolu-</cell></row><row><cell>Segmentation</cell><cell>three regions of a brain tumor on</cell><cell>performance, little possibility</cell><cell>source</cell><cell>tional neural networks</cell></row><row><cell>tool</cell><cell>MRI (entire tumor, tumor core, and</cell><cell>to increase certainty using</cell><cell></cell><cell>that take four separate</cell></row><row><cell>Neuro radiology</cell><cell>enhancing tumor core) that can be</cell><cell>additional testing.</cell><cell></cell><cell>MRI imaging sequence</cell></row><row><cell>section</cell><cell>used to calculate precise volumetric</cell><cell>• No single method serves as</cell><cell></cell><cell>files as input and</cell></row><row><cell></cell><cell>measurements.</cell><cell>the agreed-upon standard;</cell><cell></cell><cell>generates three</cell></row><row><cell></cell><cell>• Context: Physicians pay attention to</cell><cell>multiple methods are utilized</cell><cell></cell><cell>segmentation labels.</cell></row><row><cell></cell><cell>changes in the size and shape of</cell><cell>depending on the purpose of</cell><cell></cell><cell>These labels are com-</cell></row><row><cell></cell><cell>tumors for making diagnoses and</cell><cell>the exam and produce</cell><cell></cell><cell>bined into a single</cell></row><row><cell></cell><cell>treatment recommendations.</cell><cell>inconsistent results.</cell><cell></cell><cell>output that is displayed</cell></row><row><cell></cell><cell>Focusing on changes at the edges</cell><cell>• Highly subjective and variable</cell><cell></cell><cell>to the user as a visual</cell></row><row><cell></cell><cell>of each region helps assess tumor</cell><cell>interpretations across different</cell><cell></cell><cell>overlay over the original</cell></row><row><cell></cell><cell>development. High variation in brain</cell><cell>radiologists.</cell><cell></cell><cell>MRI images.</cell></row><row><cell></cell><cell>tumors' appearance, shape, and</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>properties make judging its borders</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>on MRI challenging.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bone Age tool</cell><cell>• Classify a child's hand x-ray to a</cell><cell>• No absolute measure of</cell><cell>Research</cell><cell>Convolutional neural</cell></row><row><cell>Pediatrics</cell><cell>specific numeric value (number of</cell><cell>performance, little possibility</cell><cell>group not</cell><cell>networks that take a</cell></row><row><cell>Imaging</cell><cell>years and month) and classify</cell><cell>to increase certainty using</cell><cell>affiliated</cell><cell>single hand x-ray image</cell></row><row><cell></cell><cell>whether that value is considered</cell><cell>additional testing.</cell><cell>with</cell><cell>as input and first</cell></row><row><cell></cell><cell>"normal" or "abnormal."</cell><cell>• Multiple standards and</cell><cell>Urbanside</cell><cell>generate a classification</cell></row><row><cell></cell><cell>• Context: Skeletal age, compared to</cell><cell>methods are available;</cell><cell></cell><cell>of the number of months</cell></row><row><cell></cell><cell>a child's chronological age, is critical</cell><cell>physicians use different</cell><cell></cell><cell>and number of years</cell></row><row><cell></cell><cell>for managing growth disorders in</cell><cell>medical atlases and analytical</cell><cell></cell><cell>and then assign a</cell></row><row><cell></cell><cell>children. To assess the stage of a</cell><cell>approaches within and across</cell><cell></cell><cell>"normal" or "abnormal"</cell></row><row><cell></cell><cell>child's growth development, a hand</cell><cell>hospitals.</cell><cell></cell><cell>classification. These</cell></row><row><cell></cell><cell>x-ray is compared against a medical</cell><cell>• Highly subjective and variable</cell><cell></cell><cell>outputs are presented to</cell></row><row><cell></cell><cell>atlas containing a series of images</cell><cell>interpretations across different</cell><cell></cell><cell>the user in an auto-</cell></row><row><cell></cell><cell>to identify the closest match.</cell><cell>radiologists and within the</cell><cell></cell><cell>populated report</cell></row><row><cell></cell><cell></cell><cell>same radiologist at separate</cell><cell></cell><cell>template.</cell></row><row><cell></cell><cell></cell><cell>times of observation (De</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Sanctis et al. 2014).</cell><cell></cell><cell></cell></row><row><cell>Breast Mammo</cell><cell>• Segment abnormal regions on a</cell><cell>• Highly subjective and variable</cell><cell>Research</cell><cell>Convolutional neural</cell></row><row><cell>tool</cell><cell>mammogram image and classify</cell><cell>diagnosis and follow-up</cell><cell>group</cell><cell>networks input a single</cell></row><row><cell>Breast imaging</cell><cell>each region to a "malignant" or</cell><cell>recommendations across</cell><cell>affiliated</cell><cell>mammogram, which is</cell></row><row><cell>section</cell><cell>"benign" output.</cell><cell>radiologists (Duijm et al.</cell><cell>with</cell><cell>first segmented to iden-</cell></row><row><cell></cell><cell>• Context: Mammography screening</cell><cell>2009). Up to 12% of breast</cell><cell>Urbanside</cell><cell>tify all lesions present.</cell></row><row><cell></cell><cell>is the most popular tool for early</cell><cell>cancers in the U.S. are missed</cell><cell></cell><cell>Each lesion is then</cell></row><row><cell></cell><cell>breast cancer detection. Typically</cell><cell>during initial mammography.</cell><cell></cell><cell>classified as "malignant"</cell></row><row><cell></cell><cell>abnormal regions are identified by</cell><cell>Of the 9-10% of patients</cell><cell></cell><cell>or "benign." These</cell></row><row><cell></cell><cell>analyzing and integrating numerous</cell><cell>recalled for additional imaging,</cell><cell></cell><cell>results are aggregated</cell></row><row><cell></cell><cell>sources of medical information and</cell><cell>less than half are found to</cell><cell></cell><cell>to an image-level proba-</cell></row><row><cell></cell><cell>inputs. When a region is judged as</cell><cell>have breast cancer (Lehman</cell><cell></cell><cell>bility of malignancy.</cell></row><row><cell></cell><cell>likely to be malignant, the patient is</cell><cell>et al. 2017).</cell><cell></cell><cell>Users see an overlay of</cell></row><row><cell></cell><cell>often recommended for biopsy or</cell><cell>• Professional standards sug-</cell><cell></cell><cell>circles marking "malig-</cell></row><row><cell></cell><cell>additional imaging to make the final</cell><cell>gest the use of additional</cell><cell></cell><cell>nant" lesions on the</cell></row><row><cell></cell><cell>diagnosis.</cell><cell>imaging modalities (MRI,</cell><cell></cell><cell>original mammogram</cell></row><row><cell></cell><cell></cell><cell>ultrasound), performing</cell><cell></cell><cell>image as well as the</cell></row><row><cell></cell><cell></cell><cell>biopsies, or obtaining long-</cell><cell></cell><cell>image's overall</cell></row><row><cell></cell><cell></cell><cell>term patient records.</cell><cell></cell><cell>"malignancy score."</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Nature of the Tool's Diagnostic Task Measure of the Performance of the Diagnosis Task Tool Source Tool Design</head><label></label><figDesc></figDesc><table><row><cell>Breast</cell><cell>• Classify (physician-marked) lesion</cell><cell>• Regular disagreement</cell><cell>Vendor</cell><cell>Patented software</cell></row><row><cell>Ultrasound tool</cell><cell>on ultrasound image into one of four</cell><cell>between radiologists on final</cell><cell></cell><cell>design using an</cell></row><row><cell>Breast imaging</cell><cell>diagnosis categories (benign,</cell><cell>diagnosis categorization of</cell><cell></cell><cell>ensemble of machine-</cell></row><row><cell>section</cell><cell>probably benign, suspicious, or</cell><cell>ultrasound findings; higher</cell><cell></cell><cell>learning algorithms that</cell></row><row><cell></cell><cell>probably malignant) with the</cell><cell>concordance reported for</cell><cell></cell><cell>takes two regions-of-</cell></row><row><cell></cell><cell>associated confidence level, and</cell><cell>lesion size, shape, and</cell><cell></cell><cell>interest (drawn by the</cell></row><row><cell></cell><cell>classify the lesion's shape and</cell><cell>orientation (Lazarus et al.</cell><cell></cell><cell>physician user) on an</cell></row><row><cell></cell><cell>orientation.</cell><cell>2006).</cell><cell></cell><cell>ultrasound image as</cell></row><row><cell></cell><cell>• Context: Physicians often cross-</cell><cell>• Professional standards</cell><cell></cell><cell>input and classifies the</cell></row><row><cell></cell><cell>validate abnormal regions identified</cell><cell>suggest the use of additional</cell><cell></cell><cell>lesion's diagnostic</cell></row><row><cell></cell><cell>on a mammogram to their appear-</cell><cell>imaging modalities (MRI,</cell><cell></cell><cell>category, associated</cell></row><row><cell></cell><cell>ance on ultrasound, which provides</cell><cell>mammogram), performing</cell><cell></cell><cell>confidence level, and</cell></row><row><cell></cell><cell>additional information to inform</cell><cell>biopsies, or obtaining long-</cell><cell></cell><cell>shape and orientation.</cell></row><row><cell></cell><cell>physicians' diagnosis, such as the</cell><cell>term patient outcomes.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>lesion size, shape, and whether it is</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>solid or fluid-filled.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Chest Triage tool</cell><cell></cell><cell>• Highly subjective and variable</cell><cell></cell><cell></cell></row><row><cell>Chest imaging</cell><cell></cell><cell>diagnosis interpretations and</cell><cell></cell><cell></cell></row><row><cell>section</cell><cell></cell><cell>follow-up recommendations</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>among different radiologists</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>based on the same chest x-</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>ray.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>• Professional standard</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>suggests the use of additional</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>imaging and modalities (CT</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>scan) or follow-up studies.</cell><cell></cell><cell></cell></row></table><note><p>• Classify chest x-ray into one of 14 disease categories (e.g., pneumonia, pleural effusion, cardiomegaly) and classify whether that outcome is considered "normal" or "abnormal," which is then used to prioritize the work queue. • Context: Chest x-ray is the most common imaging examination globally, as it is critical for the diagnosis and management of many diseases. As physicians analyze cases, the work queue grows longer and longer, and typically utilization a prioritization based on coming from the emergency department, then on a first-in-first-out basis.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 . Summarizing the Shifting Focus Across Quality Measures While Evaluating ML-Based AI Tools for Medical Diagnosis</head><label>2</label><figDesc></figDesc><table><row><cell>Focus of</cell><cell>Brain Tumor</cell><cell></cell><cell></cell><cell></cell><cell>Breast Ultrasound</cell></row><row><cell>Evaluation</cell><cell>Segmentation Tool</cell><cell>Bone Age Tool</cell><cell>Breast Mammo Tool</cell><cell>Chest Triage Tool</cell><cell>Tool</cell></row><row><cell>Reported</cell><cell>Focusing on pro-</cell><cell>Focusing on pro-</cell><cell>Focusing on promises</cell><cell>Focusing on pro-</cell><cell>Focusing on promises</cell></row><row><cell>claims of AI</cell><cell>mises to increase</cell><cell>mises to reduce</cell><cell>to improve diagnosis</cell><cell>mises to reduce</cell><cell>to improve diagnosis</cell></row><row><cell>tools' high</cell><cell>diagnosis accuracy</cell><cell>diagnosis time and</cell><cell>accuracy and possibly</cell><cell>diagnosis times and</cell><cell>accuracy and possibly</cell></row><row><cell>quality</cell><cell>by adding a precise</cell><cell>improve diagnosis</cell><cell>spend less time</cell><cell>improve outcomes</cell><cell>reducing time</cell></row><row><cell></cell><cell>measurement to</cell><cell>accuracy with tool-</cell><cell>reading "normal"</cell><cell>by detecting and</cell><cell>physicians spend</cell></row><row><cell></cell><cell>physicians' analysis</cell><cell>generated</cell><cell>mammograms</cell><cell>prioritizing urgent</cell><cell>equivocating</cell></row><row><cell></cell><cell></cell><cell>assessment</cell><cell></cell><cell>cases</cell><cell></cell></row><row><cell>AI tools'</cell><cell>Assessing the</cell><cell>Assessing the</cell><cell>Assessing the</cell><cell>Assessing the</cell><cell>Assessing the</cell></row><row><cell>reported AUC</cell><cell>reported perfor-</cell><cell>reported accuracy</cell><cell>reported accuracy of</cell><cell>reported accuracy of</cell><cell>reported accuracy of</cell></row><row><cell>measures</cell><cell>mance of 0.79, 0.91,</cell><cell>of 0.989 for</cell><cell>0.93 for classifying</cell><cell>between 0.90 and</cell><cell>0.88, surpassing the</cell></row><row><cell></cell><cell>0.84 for matching</cell><cell>matching within 12</cell><cell>images with malig-</cell><cell>0.97 for 13 disease</cell><cell>mean accuracy of</cell></row><row><cell></cell><cell>experts' outputs for</cell><cell>months of experts'</cell><cell>nant findings, sur-</cell><cell>categories, and 0.85</cell><cell>experts' by</cell></row><row><cell></cell><cell>respective tumor</cell><cell>assessment of</cell><cell>passing radiologists'</cell><cell>for one disease</cell><cell>approximately 0.05</cell></row><row><cell></cell><cell>regions</cell><cell>normal vs.</cell><cell>AUC by 0.11</cell><cell>category</cell><cell></cell></row><row><cell></cell><cell></cell><cell>abnormal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"Ground truth"</cell><cell>Consisted of manual</cell><cell>Consisted of the</cell><cell>Consisted of biopsy</cell><cell>Consisted of diag-</cell><cell>Consisted of pathology</cell></row><row><cell>used to train</cell><cell>segmentations</cell><cell>average of the</cell><cell>results performed</cell><cell>noses provided by</cell><cell>or a physician's diag-</cell></row><row><cell>and validate</cell><cell>drawn by one of four</cell><cell>assessments of</cell><cell>within 120 days of the</cell><cell>four radiologists who</cell><cell>noses at 1-year follow-</cell></row><row><cell>AI tools</cell><cell>experts following the</cell><cell>three fellowship-</cell><cell>mammogram</cell><cell>had four, seven, 25,</cell><cell>up (for cases not</cell></row><row><cell></cell><cell>same protocol, then</cell><cell>trained pediatric</cell><cell></cell><cell>and 28 years of</cell><cell>biopsied)</cell></row><row><cell></cell><cell>revised and ap-</cell><cell>radiologists with</cell><cell></cell><cell>experience (one was</cell><cell></cell></row><row><cell></cell><cell>proved by a board-</cell><cell>nine, eight, and two</cell><cell></cell><cell>subspecialty trained)</cell><cell></cell></row><row><cell></cell><cell>certified neuro-</cell><cell>years of post-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>radiologist</cell><cell>fellowship</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>experience</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Internal</cell><cell>Comparing tool</cell><cell>Comparing tool</cell><cell>Comparing tool out-</cell><cell>Comparing tool out-</cell><cell>Comparing tool out-</cell></row><row><cell>measures of</cell><cell>outputs to segmen-</cell><cell>outputs to diagnosis</cell><cell>puts to diagnosis</cell><cell>puts to the consen-</cell><cell>puts to pathology</cell></row><row><cell>quality for</cell><cell>tation labels pro-</cell><cell>labels of the aver-</cell><cell>labels provided by</cell><cell>sus of two senior</cell><cell>results (for cases with</cell></row><row><cell>pilot studies</cell><cell>vided by one senior</cell><cell>age of two pediatric</cell><cell>one breast radiologist,</cell><cell>chest radiologists'</cell><cell>biopsy), 3-month</cell></row><row><cell></cell><cell>neuroradiologist,</cell><cell>radiologists'</cell><cell>then aggregated to</cell><cell>assessments, then</cell><cell>follow-up of one radi-</cell></row><row><cell></cell><cell>then aggregated to</cell><cell>assessments, then</cell><cell>generate AUC-like</cell><cell>aggregated to</cell><cell>ologist (when recom-</cell></row><row><cell></cell><cell>generate AUC-like</cell><cell>aggregated to</cell><cell>measures</cell><cell>generate AUC-like</cell><cell>mended), or one</cell></row><row><cell></cell><cell>measures</cell><cell>generate AUC</cell><cell></cell><cell>measures</cell><cell>radiologist's assess-</cell></row><row><cell></cell><cell></cell><cell>measures</cell><cell></cell><cell></cell><cell>ment (majority of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>cases), then aggre-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>gated to generate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AUC-like measures</cell></row><row><cell>Comparing</cell><cell>Comparing the</cell><cell>Comparing how the</cell><cell>Comparing how</cell><cell>Comparing how</cell><cell>Comparing the</cell></row><row><cell>the AI</cell><cell>pristine research-</cell><cell>tool was deter-</cell><cell>experts produced</cell><cell>ground truth labels</cell><cell>creators' decision of a</cell></row><row><cell>process to</cell><cell>grade images used</cell><cell>mining a given out-</cell><cell>ground truth labels</cell><cell>classified certain</cell><cell>limited scope of</cell></row><row><cell>experts'</cell><cell>in the limited dataset</cell><cell>put to the multiple</cell><cell>using practices that</cell><cell>diseases as "abnor-</cell><cell>information to train the</cell></row><row><cell>process</cell><cell>to the messy and</cell><cell>standards and pro-</cell><cell>did not adhere to their</cell><cell>mal" vs. "normal"</cell><cell>tool to the wide array</cell></row><row><cell></cell><cell>nuanced reality of</cell><cell>tocols local experts</cell><cell>professional</cell><cell>and deciding to</cell><cell>of evidence experts</cell></row><row><cell></cell><cell>measuring tumor</cell><cell>were trained to use</cell><cell>standards</cell><cell>change those labels</cell><cell>consider in practice</cell></row><row><cell></cell><cell>development</cell><cell>in practice</cell><cell></cell><cell>for their internal use</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>case</cell><cell></cell></row><row><cell>Confronting</cell><cell>Confronting whether</cell><cell>Confronting whether</cell><cell>Confronting the trade-</cell><cell>Confronting whether</cell><cell>Confronting the trade-</cell></row><row><cell>limits of</cell><cell>expert labels were a</cell><cell>the expert labels</cell><cell>offs of evaluating</cell><cell>experts' diagnoses</cell><cell>offs of evaluating</cell></row><row><cell>evaluating</cell><cell>valid measure of</cell><cell>were a valid mea-</cell><cell>based on highly</cell><cell>are a valid quality</cell><cell>based on highly</cell></row><row><cell>their own</cell><cell>quality when they</cell><cell>sure of quality when</cell><cell>variable experts'</cell><cell>measure when they</cell><cell>variable experts'</cell></row><row><cell>performance</cell><cell>lacked a single,</cell><cell>they are highly</cell><cell>diagnoses vs. the</cell><cell>are highly variable</cell><cell>diagnoses vs. the</cell></row><row><cell>as experts</cell><cell>agreed-upon stan-</cell><cell>variable and subjec-</cell><cell>(highly expensive and</cell><cell>and subjective</cell><cell>(highly expensive and</cell></row><row><cell></cell><cell>dard for measuring</cell><cell>tive and based on</cell><cell>often inaccessible)</cell><cell></cell><cell>often inaccessible)</cell></row><row><cell></cell><cell>brain tumor volume</cell><cell>multiple standards</cell><cell>professional standard</cell><cell></cell><cell>professional standard</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 . The Quality Measures of Know-What and Know-How Used to Evaluate ML-Based AI Tools Measure Description How Managers Evaluated the Measure</head><label>3</label><figDesc></figDesc><table><row><cell>Ground truth</cell><cell>• Data labels assigned to every data point in training</cell><cell>• Focusing on assessing experts and their outputs (know-what)</cell></row><row><cell>measures</cell><cell>and validation datasets which form the basis of a</cell><cell>that are used to train the model to generate its outputs.</cell></row><row><cell></cell><cell>ML model's ability to match new inputs to outputs</cell><cell>• Asking, how well do the labels represent "accurate" outcomes</cell></row><row><cell></cell><cell>• Constructed by AI creators</cell><cell>for a given input?</cell></row><row><cell></cell><cell>• Represented prominently in AI literature on ML</cell><cell>• Asking, what is the caliber and qualification of the experts</cell></row><row><cell></cell><cell></cell><cell>generating labels?</cell></row><row><cell>Professional</cell><cell>• The most accurate or best available benchmark for</cell><cell>• Focusing on assessing experts and their outputs (know-what)</cell></row><row><cell>standard of</cell><cell>establishing the accuracy of a given knowledge</cell><cell>• Asking, does the professional field endorse the use of this</cell></row><row><cell>output quality</cell><cell>output given current conditions</cell><cell>standard?</cell></row><row><cell></cell><cell>• Set in the context of a professional field</cell><cell>• Sometimes standards are represented in the AI literature, for</cell></row><row><cell></cell><cell>• Occasionally represented in AI literature</cell><cell>example, does the ground truth use the best available</cell></row><row><cell></cell><cell>• Standards vary from those that use aggregated</cell><cell>standard established by the professional field?</cell></row><row><cell></cell><cell>opinions of experts to those derived from external</cell><cell></cell></row><row><cell></cell><cell>validations derived from biopsies and long-term</cell><cell></cell></row><row><cell></cell><cell>follow-up</cell><cell></cell></row><row><cell>AI accuracy</cell><cell>• In the image recognition models in our study, ML-</cell><cell>• Focusing on assessing ML-based AI outputs (know-what)</cell></row><row><cell>measures</cell><cell>based AI outputs are summarized by AUC</cell><cell>• Asking, how close is the AUC measure to 1.0? A measure of</cell></row><row><cell></cell><cell>measures which compare how well AI outputs</cell><cell>1.0 suggests the ML-based AI model's know-what perfectly</cell></row><row><cell></cell><cell>match predefined ground truth labels</cell><cell>aligns with experts' know-what.</cell></row><row><cell></cell><cell>• Represented prominently in AI literature and</cell><cell>• Asking, how does the ML-based AI model's error rates</cell></row><row><cell></cell><cell>publicly reported documentation</cell><cell>compare to experts' error rates?</cell></row><row><cell></cell><cell></cell><cell>• Weighing the relative risks and benefits of tradeoffs between</cell></row><row><cell></cell><cell></cell><cell>false positive and false negative types of errors.</cell></row><row><cell>Practically</cell><cell>• The accumulated professional know-how practices</cell><cell></cell></row><row><cell>acceptable</cell><cell>that enable experts to reach an adequate level of</cell><cell></cell></row><row><cell>performance</cell><cell>certainty in a situated problem context</cell><cell></cell></row><row><cell></cell><cell>• Constituted in daily professional life</cell><cell></cell></row><row><cell></cell><cell>• Rarely represented in AI literature on ML</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>In two cases (bone age and brain tumor segmentation), multiple standards were used unsystematically and yielded varied (yet equally acceptable) diagnosis outputs. For the two breast cancer diagnosis tools, expert-generated labels were commonly used for evaluation instead of enduring the costs of acquiring the level of evidence defined by the established professional standard.</figDesc><table><row><cell>Finally, aggregated AI performance accuracy measures were</cell></row><row><cell>the third quality measure based on know-what that influenced</cell></row><row><cell>and limited managers' AI evaluations. Managers focused</cell></row><row><cell>specifically on AUC measures, a numeric representation of</cell></row><row><cell>how well an AI model's outputs matched predefined ground</cell></row><row><cell>truth labels. Managers viewed AUC measures as objective</cell></row><row><cell>indicators of the quality of the AI tool. They often failed to</cell></row><row><cell>appreciate how the AUC measure obscured the uncertain</cell></row><row><cell>knowledge represented in ground truth labels and how it</cell></row><row><cell>failed to account for experts' know-how practices.</cell></row><row><cell>Quality measure of know-how. This study distinguishes</cell></row><row><cell>between the previous three quality measures of know-what</cell></row><row><cell>from a quality measure based on know-how. This measure is</cell></row><row><cell>associated with experts applying rich professional know-how</cell></row><row><cell>practices to reach an adequate level of certainty for a situated</cell></row><row><cell>problem context. In many fields, this involves experts</cell></row><row><cell>accepting that full certainty may be impossible to achieve</cell></row><row><cell>given the current state of knowledge in that field and practical</cell></row><row><cell>costs and constraints. Using a quality measure of know-how</cell></row><row><cell>in practice means evaluating experts based on their ability to</cell></row><row><cell>demonstrate the range of tacit practices they have accu-</cell></row><row><cell>mulated over time that enable them to form practically accep-</cell></row><row><cell>table judgments. In our study, we show how managers</cell></row><row><cell>ultimately confronted the disconnect between experts' know-</cell></row><row><cell>how-based measures and the know-what-based measures used</cell></row><row><cell>for evaluating ML-based AI tools.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 . Theoretical Implications of the ML-Based AI Tools Evaluation on Professional Knowledge Work</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell>Evaluation</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Based on</cell><cell></cell><cell></cell></row><row><cell>Focus of</cell><cell>Know-What or</cell><cell>Relationship Between Know-What</cell><cell></cell></row><row><cell>Evaluation</cell><cell>Know-How</cell><cell>and Know-How</cell><cell>Questions for Future Research</cell></row><row><cell>Ground truth</cell><cell>Based on</cell><cell>• Know-what knowledge outputs fail to</cell><cell>• When and how does an introduction of ML tools into a</cell></row><row><cell>measures</cell><cell>know-what</cell><cell>capture the richness of experts' tacit</cell><cell>professional field increase the propensity to codify know-</cell></row><row><cell></cell><cell></cell><cell>know-how practices yet are taken for</cell><cell>what of practice to enable ML tools?</cell></row><row><cell></cell><cell></cell><cell>granted as "the truth" if produced by</cell><cell></cell></row><row><cell></cell><cell></cell><cell>trained experts.</cell><cell></cell></row><row><cell>Professional</cell><cell>Based on</cell><cell>• Standards based on know-what may</cell><cell>• How do professional standards of know-what in a field</cell></row><row><cell>standard of</cell><cell>know-what</cell><cell>be taken-for-granted as objective</cell><cell>change with the introduction of ML tools?</cell></row><row><cell>output</cell><cell></cell><cell>and reliable knowledge in a field, but</cell><cell>• Does the introduction of ML tools lead to convergence of</cell></row><row><cell>quality</cell><cell></cell><cell>when the underlying knowledge is</cell><cell>professional standards of know-what even in areas where</cell></row><row><cell></cell><cell></cell><cell>uncertain, such standards will not be</cell><cell>know-what knowledge is uncertain and standard creation</cell></row><row><cell></cell><cell></cell><cell>met consistently.</cell><cell>is less mature?</cell></row><row><cell></cell><cell></cell><cell>• Reliable professional standards of</cell><cell>• Do professional standards "degrade" towards those that</cell></row><row><cell></cell><cell></cell><cell>know-what are often costly to obtain</cell><cell>are easier to obtain at scale?</cell></row><row><cell></cell><cell></cell><cell>at scale.</cell><cell>• Will we see the rise of new types of professional</cell></row><row><cell></cell><cell></cell><cell></cell><cell>standards pertaining to AI-augmented work?</cell></row><row><cell>Performanc</cell><cell>Based on</cell><cell>• Aggregating accuracy measures into</cell><cell>• How do AUC measures influence managerial decisions of</cell></row><row><cell>e accuracy</cell><cell>know-what</cell><cell>a single AUC measure obscures the</cell><cell>whether to use ML tools to augment or replace human</cell></row><row><cell>measures</cell><cell></cell><cell>trade-offs made in the construction</cell><cell>experts?</cell></row><row><cell>(AUC)</cell><cell></cell><cell>of the underlying ground truth</cell><cell>• What are the risks of comparing human and ML tool per-</cell></row><row><cell></cell><cell></cell><cell>measures.</cell><cell>formance based on an AUC measure, if ML tools are</cell></row><row><cell></cell><cell></cell><cell></cell><cell>trained to optimize this measure, while human experts</cell></row><row><cell></cell><cell></cell><cell></cell><cell>optimize multiple performance outputs?</cell></row><row><cell>Practically</cell><cell>Based on</cell><cell>• Know-how is difficult to codify in</cell><cell></cell></row><row><cell>acceptable</cell><cell>know-how</cell><cell>know-what outputs since know-how</cell><cell></cell></row><row><cell>performance</cell><cell></cell><cell>is based on tacit, social, situated,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>and embedded action performed</cell><cell></cell></row><row><cell></cell><cell></cell><cell>over time.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>• Know-how measures are the only</cell><cell></cell></row><row><cell></cell><cell></cell><cell>"measure of quality" available when</cell><cell></cell></row><row><cell></cell><cell></cell><cell>knowledge is highly uncertain.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>• As learning unfolds through</cell><cell></cell></row><row><cell></cell><cell></cell><cell>reflection-in-action, know-how</cell><cell></cell></row><row><cell></cell><cell></cell><cell>knowledge evolves; know-what</cell><cell></cell></row><row><cell></cell><cell></cell><cell>knowledge cannot improve without</cell><cell></cell></row><row><cell></cell><cell></cell><cell>know-how.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>"AUC" and "ROC" (Receiver Operator Curve) are commonly used interchangeably in practice.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Examples can be found at https://www.kaggle.com/competitions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>See the American College of Radiology's Data Science Institute at www.acrdsi.org and Radiology Society of North America at www.rsna.org/education/ai-resources-and-training.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>For instance, multiple conclusions may be drawn if a patient never returns to the physician: Was the diagnosis and subsequent treatment accurate and the patient recovered? Was the diagnosis inaccurate, but the patient recovered anyway? Was the diagnosis inaccurate, and the patient worsened, yet never returned to the original physician?</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Gathering such assessments are often part of standard medical practices, including routine peer reviews, regular conferencing with other physicians in a patient care team, in addition to the frequent impromptu meetings or phone calls wherein colleagues discuss a current diagnostic question, examine and debating case details together, until agreeing on a unified conclusion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>MISQuarterly Vol. 45 No. 3 / September 2021</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers and the special issue editors for their instrumental comments and insights throughout the review process. We appreciate the helpful feedback provided by <rs type="person">Foster Provost</rs>, <rs type="person">Beth Bechky</rs>, and <rs type="person">Susan Scott</rs> as well as researchers at the <rs type="institution" subtype="infrastructure">ICIS 2020 AI in Practice PDW and in the Work in the Age of Intelligent Machines (WAIM) community</rs>. Finally, we are deeply grateful for and inspired by the individuals at "Urbanside" who generously allowed us to study their daily work.</p></div>
			</div>
			<listOrg type="infrastructure">
				<org type="infrastructure">					<orgName type="extracted">ICIS 2020 AI in Practice PDW and in the Work in the Age of Intelligent Machines (WAIM) community</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About the Authors</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The System of Professions: An Essay on the Division of Expert Labor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abbott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>University of Chicago Press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Machine Bias</title>
		<author>
			<persName><forename type="first">J</forename><surname>Angwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kirchner</surname></persName>
		</author>
		<ptr target="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" />
	</analytic>
	<monogr>
		<title level="j">ProPublica</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">To Question or Accept? How Status Differences Influence Responses to New Epistemic Technologies in Knowledge Work</title>
		<author>
			<persName><forename type="first">C</forename><surname>Anthony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="661" to="679" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-to-End Lung Cancer Screening with Three-Dimensional Deep Learning on Low-Dose Chest Computed Tomography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Kiraly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Reicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Etemadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Naidich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="954" to="961" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Why Are There Still So Many Jobs? The History and Future of Workplace Automation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Autor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="30" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barredo Arrieta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Díaz-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bennetot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tabik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barbado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gil-Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benjamins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chatila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="issue">58</biblScope>
			<biblScope unit="page" from="82" to="115" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Expl(AI)n It to Me-Explainable AI and Information Systems Research</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Business &amp; Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="82" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Object Lessons: Workplace Artifacts as Representations of Occupational Jurisdiction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bechky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="720" to="752" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Blood, Powder, and Residue: How Crime Labs Translate Evidence into Proof</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Bechky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised by Any Other Name: Hidden Layers of Knowledge Production in Artificial Intelligence on Social Media</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Bowker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Luckmann</surname></persName>
		</author>
		<title level="m">The Social Construction of Reality: A Treatise in the Sociology of Knowledge</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Anchor Books</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overconfidence as a Cause of Diagnostic Error in Medicine</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="S2" to="S23" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Supplement</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Bowker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Star</surname></persName>
		</author>
		<title level="m">Sorting Things Out: Classification and Its Consequences</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Organizational Learning and Communities-of-Practice: Toward a Unified View of Working, Learning, and Innovation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duguid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="57" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledge and Organization: A Social-Practice Perspective</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duguid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="198" to="213" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Understanding and Confronting Our Mistakes: The Epide-miology of Error in Radiology and Strategies for Error Reduction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Abujudeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RadioGraphics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1668" to="1676" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RADEX-Towards a Computer-Based Radiology Consultant</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition in</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Practice</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Gelsema</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North Holland</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="463" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Constructing Grounded Theory</title>
		<author>
			<persName><forename type="first">K</forename><surname>Charmaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>SAGE Publications</publisher>
			<pubPlace>Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">When it Comes to Chasing Clicks, Journalists Say One Thing but Feel Pressure to Do Another</title>
		<author>
			<persName><forename type="first">A</forename><surname>Christin</surname></persName>
		</author>
		<ptr target="http://www.niemanlab.org/2014/08/when-it-comes-to-chasing-clicks-journalists-say-one-thing-but-feel-pressure-to-do-another/" />
		<imprint>
			<date type="published" when="2014-10-18">2014. October 18, 2018</date>
		</imprint>
		<respStmt>
			<orgName>Nieman Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Ethnographer and the Algorithm: Beyond the Black Box</title>
		<author>
			<persName><forename type="first">A</forename><surname>Christin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Society</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="897" to="918" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving Accuracy and Efficiency with Concurrent Use of Artificial Intelligence for Digital Breast Tomosynthesis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Conant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Toledano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Periaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Fotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Boatsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Hoffmeister</surname></persName>
		</author>
		<idno type="DOI">10.1148/ryai.2019180096</idno>
	</analytic>
	<monogr>
		<title level="j">Radiology Artificial Intelligence</title>
		<imprint>
			<biblScope unit="issue">1:4</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Broken &apos;Two-Way Windows&apos;? An Exploration of Professional Hybrids</title>
		<author>
			<persName><forename type="first">C</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Currie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Administration</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="380" to="394" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hand X-Ray in Pediatric Endocrinology: Skeletal Age Assessment and Beyond</title>
		<author>
			<persName><forename type="first">V</forename><surname>De Sanctis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Di Maio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raiola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Elalaily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Millimaggi</surname></persName>
		</author>
		<idno>pp. S63-S71</idno>
	</analytic>
	<monogr>
		<title level="j">Indian Journal of Endocrinology and Metabolism</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">Suppl 1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2009 IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">When to Trust Robots with Decisions, and When Not To</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Digital Science and Knowledge Boundaries in Complex Innovation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dougherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Dunne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1467" to="1484" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Dreyfus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Dreyfus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Athanasiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind Over Machine</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Simon and Schuster</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Inter-Observer Variability in Mammography Screening and Effect of Type and Number of Readers on Screening Outcome</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E M</forename><surname>Duijm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W J</forename><surname>Louwman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Groenewoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Van De Poll-Franse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fracheboud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Coebergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Cancer</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="901" to="907" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Sociology of Quantification</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Espeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Sociology/Archives Européennes de Sociologie</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="436" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Working and Organizing in the Age of the Learning Algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Faraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pachidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sayegh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Organization</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="70" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Culture of Objectivity: Quantification, Uncertainty, and the Evaluation of Risk at NASA</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Relations</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="691" to="718" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Method to Link Advances in Artificial Intelligence to Occupational Abilities</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Felten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Seamans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AEA Papers and Proceedings</title>
		<imprint>
			<biblScope unit="issue">108</biblScope>
			<biblScope unit="page" from="54" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Explaining Data-Driven Decisions Made by AI Systems: The Counterfactual Approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fernández-Loría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<idno>ArXiv:2001.07417</idno>
		<ptr target="http://arxiv.org/abs/2001.07417" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Engineering Knowledge: The Construction of Knowledge in Artificial Intelligence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Forsythe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Studies of Science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="445" to="477" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Future of Employment: How Susceptible Are Jobs to Computerisation?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="issue">114</biblScope>
			<biblScope unit="page" from="254" to="280" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the Distinction between Know-How, Know-What, and Know-Why</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Strategic Management</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="81" to="102" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The Data That Transformed AI Researchand Possibly the World</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gershgorn</surname></persName>
		</author>
		<ptr target="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Quartz</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Gitelman</surname></persName>
		</author>
		<title level="m">Raw Data&quot; Is an Oxymoron</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Crisis as Opportunity, Disruption and Exposure: Exploring Emergent Responses to Crisis through Digital Technology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gkeredakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lifshitz-Assaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Organization</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Discovering Grounded Theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strauss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1967</date>
			<publisher>Aldine Publishing Company</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Golden-Biddle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Locke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Composing Qualitative Research</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>SAGE Publications</publisher>
			<pubPlace>Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A.I. Took a Test to Detect Lung Cancer. It Got an A</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grady</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2019/05/20/health/cancer-artificial-intelligence-ct-scans.html" />
	</analytic>
	<monogr>
		<title level="j">The New York Times</title>
		<imprint>
			<date type="published" when="2019-05-20">2019. May 20</date>
		</imprint>
	</monogr>
	<note>Health</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Survey of Methods for Explaining Black Box Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Cognition in the Wild</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hutchins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Epistemic Cultures. How the Sciences Make Knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Knorr Cetina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">What If the Screens Went Black? The Coming of Software Agents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Knorr Cetina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Beyond Interpretivism? New Encounters with Technology and Organizations, L. Introna</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Kavanah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Orlikowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Scott</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Knowledge of the Firm, Combinative Capabilities, and the Replication of Technology</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kogut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="383" to="397" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Glossary of Terms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="271" to="274" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Ground Truth Data, Content, Metrics, and Analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Metrics: Survey, Taxonomy, and Analysis</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="247" to="271" />
		</imprint>
	</monogr>
	<note>Chapter</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Will Artificial Intelligence Replace Radiologists?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019">2019. 190058</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science in Action: How to Follow Scientists and Engineers through Society</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Lave</surname></persName>
		</author>
		<title level="m">Cognition in Practice: Mind, Mathematics and Culture in Everyday Life</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">BI-RADS Lexicon for US and Mammography: Interobserver Variability and Positive Predictive Value</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lazarus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Mainiero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schepps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Koelliker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Livingston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="385" to="391" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Diagnostic Doubt and Artificial Intelligence: An Inductive Field Study of Radiology Work</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lebovitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40 th International Conference on Information Systems</title>
		<meeting>the 40 th International Conference on Information Systems<address><addrLine>Munich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">National Performance Benchmarks for Modern Screening Digital Mammography: Update from Breast Cancer Surveillance Consortium</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Arao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Sprague</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S M</forename><surname>Buist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kerlikowske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Onega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N A</forename><surname>Tosteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Rauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Miglioretti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Wellsprings of Knowledge: Building and Sustaining the Sources of Innovation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Leonard-Barton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Harvard Business School Press</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Minimal and Adaptive Coordination: How Hackathons&apos; Projects Accelerate Innovation Without Killing It</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lifshitz-Assaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lebovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zalmanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Journal</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="684" to="715" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Hybrid Manager-Professionals&apos; Identity Work: The Maintenance and Hybridization of Medical Professionalism in Managerial Contexts</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mcgivern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Currie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferlie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waring</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Administration</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="412" to="432" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Decisions about Knowledge in Medical Practice: The Effect of Temporal Features of a Task</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Menchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="701" to="749" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Integrating Knowledge in the Face of Epistemic Uncertainty: Dialogically Drawing Distinctions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mengis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nicolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Swan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Learning</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="595" to="612" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Challenges of Ground Truth Evaluation of Multi-Target Tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">LEAP: A Learning Apprentice for VLSI Design</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mabadevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Steinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Kodratoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Michalski</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="271" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Acoustic Modeling Using Deep Belief Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="22" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mongan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e200029</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">This Artificial Intelligence Won&apos;t Take Your Job, it Will Help You Do it Better</title>
		<author>
			<persName><forename type="first">G</forename><surname>Moran</surname></persName>
			<affiliation>
				<orgName type="collaboration">Fast Company</orgName>
			</affiliation>
		</author>
		<ptr target="https://www.fastcompany.com/90253977/this-artificial-intelligence-wont-take-your-job-it-will-help-you-do-it-better" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The New Yorker</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Versus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename></persName>
		</author>
		<ptr target="https://www.newyorker.com/magazine/2017/04/03/ai-versus-md" />
	</analytic>
	<monogr>
		<title level="j">Annals of Medicine</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Zooming In and Out: Studying Practices by Switching Theoretical Lenses and Trailing Connections</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nicolini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1391" to="1418" />
		</imprint>
	</monogr>
	<note>Organization Studies</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Practice Theory, Work, and Organization: An Introduction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nicolini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Tacit Knowledge and Knowledge Conversion: Controversy and Advancement in Organizational Knowledge Creation Theory</title>
		<author>
			<persName><forename type="first">I</forename><surname>Nonaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="635" to="652" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The Pharmaceutical Sector</title>
		<author>
			<persName><forename type="first">J</forename><surname>Northrup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Business of Healthcare Innovation</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="27" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The Rebirth of CAD: How Is Modern AI Different from the CAD We Know?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The Duality of Technology: Rethinking the Concept of Technology in Organizations</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Orlikowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="398" to="427" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Knowing in Practice: Enacting a Collective Capability in Distributed Organizing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Orlikowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="273" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">What Happens When Evaluation Goes Online? Exploring Apparatuses of Valuation in the Travel Sector</title>
		<author>
			<persName><forename type="first">W</forename><surname>Orlikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="868" to="891" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Make Way for the Algorithms: Symbolic Actions and Change in a Regime of Knowing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pachidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Berends</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Faraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huysman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="41" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">From 2016: Why Deep Learning Is Suddenly Changing Your Life</title>
		<author>
			<persName><forename type="first">R</forename><surname>Parloff</surname></persName>
		</author>
		<ptr target="https://fortune.com/longform/ai-artificial-intelligence-deep-machine-learning/" />
	</analytic>
	<monogr>
		<title level="j">Fortune</title>
		<imprint>
			<date type="published" when="2016-09-28">2016. September 28</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Pasquale</surname></persName>
		</author>
		<title level="m">The Black Box Society: The Secret Algorithms That Control Money and Information</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Reprint ed.</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Getting Comfortable with the Numbers: Auditing and the Micro-Production of Macro-Order</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accounting, Organizations and Society</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="605" to="620" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Information Systems and Organizational Learning: The Social Epistemology of Organizational Knowledge Systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accounting, Management and Information Technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The Social Construction of Facts and Artifacts: Or How the Sociology of Science and the Sociology of Technology Might Benefit Each Other</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pinch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bijker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Social Construction of Technological Systems: New Directions in the Sociology and History of Technology</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Hughes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Bijker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Pinch</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="17" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Polanyi</surname></persName>
		</author>
		<title level="m">Personal Knowledge: Towards a Post-Critical Philosophy</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Polanyi</surname></persName>
		</author>
		<title level="m">The Tacit Dimension</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Robust Classification for Imprecise Environments</title>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="231" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Sebastopol, CA: O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Sizing the Prize: What&apos;s the Real Value of AI for Your Business and How Can You Capitalise?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verweij</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-09-08">2017. September 8</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
	<note>PricewaterhouseCoopers Australia</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Rise of Robot Radiologists</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reardon</surname></persName>
		</author>
		<idno>pp. S54-S58</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">576</biblScope>
			<biblScope unit="page">7787</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Artificial Intelligence: Threat or Boon to Radiologists?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Bryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American College of Radiology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1476" to="1480" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Rindova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Courtney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To Shape or Adapt: Knowledge Problems, Epistemologies, and Strategic Postures under Knightian Uncertainty</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="787" to="807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Common Pitfalls and Recommendations for Using Machine Learning to Detect and Prognosticate for COVID-19 Using Chest Radiographs and CT Scans</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Driggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gilbey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ursprung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Aviles-Rivero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Etmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mccague</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Weir-Mccall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gkrania-Klotsas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H F</forename><surname>Rudd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Schönlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="217" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">The Concept of Mind</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ryle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">1949</date>
			<publisher>Hutcheson</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">The Reflective Practitioner: How Professionals Think in Action</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schön</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Basic Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">AI and the Economy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Seamans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Furman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovation Policy and the Economy</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="161" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14 th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 14 th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Perrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Manyika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bauer</surname></persName>
		</author>
		<title level="m">The AI Index 2018 Annual Report</title>
		<meeting><address><addrLine>Stanford, CA; Stanford University</addrLine></address></meeting>
		<imprint>
			<publisher>AI Index Steering Committee, Human-Centered AI Initiative</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Making Management Decisions: The Role of Intuition and Emotion</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Academy of Management Executive</title>
		<imprint>
			<date type="published" when="1987">1987. 1987-1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Inferring Ground Truth from Subjective Labelling of Venus Images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="1085" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">The Ethnographic Interview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Spradley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Holt, Rinehart and Winston</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">The Structure of Ill-Structured Solutions: Boundary Objects and Heterogeneous Distributed Problem Solving</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Star</surname></persName>
		</author>
		<editor>L. Gasser and M. N. Huhns</editor>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Morgan Kaufmann</publisher>
			<biblScope unit="page" from="37" to="54" />
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
	<note>in Distributed Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Star</surname></persName>
		</author>
		<title level="m">Ecologies of Knowledge: Work and Politics in Science and Technology</title>
		<meeting><address><addrLine>Albany, NY</addrLine></address></meeting>
		<imprint>
			<publisher>SUNY Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Suchman</surname></persName>
		</author>
		<title level="m">Plans and Situated Actions</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>University of Cambridge Press</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Exploring Internal Stickiness: Impediments to the Transfer of Best Practice within the Firm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Szulanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Strategic Management Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="27" to="43" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">AI, Radiology and the Future of Work</title>
		<ptr target="https://www.economist.com/leaders/2018/06/07/ai-radiology-and-the-future-of-work" />
	</analytic>
	<monogr>
		<title level="j">The Economist</title>
		<imprint>
			<date type="published" when="2018-06-08">2018. June 8</date>
		</imprint>
	</monogr>
	<note>The Economist</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">The Gold Standard: The Challenge of Evidence-Based Medicine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Timmermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Temple University Press</publisher>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Managing Data-Driven Development: An Ethnography of Developing Machine Learning for Recruitment</title>
		<author>
			<persName><forename type="first">E</forename><surname>Van Den Broek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sergeeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huysman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<publisher>Academy of Management Proceedings</publisher>
			<biblScope unit="page">17689</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Qualitative Studies of Organizations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Maanen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>SAGE Publications</publisher>
			<pubPlace>Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Von Hippel</surname></persName>
		</author>
		<title level="m">The Sources of Innovation</title>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Hotspots and Blind Spots</title>
		<author>
			<persName><forename type="first">L</forename><surname>Waardenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sergeeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huysman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Living with Monsters? Social Implications of Algorithmic Phenomena, Hybrid Agency, and the Performativity of Technology</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aanestad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Mähring</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Østerlund</surname></persName>
		</editor>
		<editor>
			<persName><surname>Riemer</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="96" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">The Growth of AI Adoption in Law Enforcement</title>
		<author>
			<persName><forename type="first">K</forename><surname>Walch</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/cognitiveworld/2019/07/26/the-growth-of-ai-adoption-in-law-enforcement/" />
	</analytic>
	<monogr>
		<title level="j">Forbes</title>
		<imprint>
			<date type="published" when="2019-07-26">2019. July 26</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Amazon Created a Hiring Tool Using A.I. It Immediately Started Discriminating Against Women</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weissmann</surname></persName>
		</author>
		<ptr target="https://slate.com/business/2018/10/amazon-artificial-intelligence-hiring-discrimination-women.html" />
	</analytic>
	<monogr>
		<title level="m">Slate, October 10</title>
		<imprint>
			<date type="published" when="2018-07-28">2018. July 28, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
