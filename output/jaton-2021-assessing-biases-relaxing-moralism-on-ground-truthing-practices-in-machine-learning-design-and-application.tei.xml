<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assessing biases, relaxing moralism: On ground-truthing practices in machine learning design and application</title>
				<funder ref="#_HSmMmAT">
					<orgName type="full">Schweizerischer Nationalfonds zur Fâ‚¬ orderung der Wissenschaftlichen Forschung</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Florian</forename><surname>Jaton</surname></persName>
						</author>
						<title level="a" type="main">Assessing biases, relaxing moralism: On ground-truthing practices in machine learning design and application</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1177/20539517211013569</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2024-12-03T20:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>algorithms</term>
					<term>machine learning</term>
					<term>artificial intelligence</term>
					<term>bias</term>
					<term>ground truth</term>
					<term>morality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This theoretical paper considers the morality of machine learning algorithms and systems in the light of the biases that ground their correctness. It begins by presenting biases not as a priori negative entities but as contingent external referents-often gathered in benchmarked repositories called ground-truth datasets-that define what needs to be learned and allow for performance measures. I then argue that ground-truth datasets and their concomitant practicesthat fundamentally involve establishing biases to enable learning procedures-can be described by their respective morality, here defined as the more or less accounted experience of hesitation when faced with what pragmatist philosopher William James called "genuine options"-that is, choices to be made in the heat of the moment that engage different possible futures. I then stress three constitutive dimensions of this pragmatist morality, as far as groundtruthing practices are concerned: (I) the definition of the problem to be solved (problematization), (II) the identification of the data to be collected and set up (databasing), and (III) the qualification of the targets to be learned (labeling). I finally suggest that this three-dimensional conceptual space can be used to map machine learning algorithmic projects in terms of the morality of their respective and constitutive ground-truthing practices. Such techno-moral graphs may, in turn, serve as equipment for greater governance of machine learning algorithms and systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Machine learning (ML) algorithms-computerized methods of calculation that infer rules of computation from sets of data to make predictions and support decision-making tasks-are now powering many commonly used devices such as Web search engines <ref type="bibr" target="#b74">(Richardson et al., 2006)</ref>, social media applications <ref type="bibr" target="#b33">(Hazelwood et al., 2018)</ref>, online purchasing platforms <ref type="bibr" target="#b72">(Portugal et al., 2018)</ref>, and surveillance systems <ref type="bibr" target="#b11">(Chokshi, 2019)</ref>. In reaction to the growing ubiquity of these statistical methods of computation-that have greatly participated in the resurrection of artificial intelligence (AI)-scholars in Science and Technology Studies (STS) 1 have accounted for some of their constitutive relationships <ref type="bibr" target="#b5">(Bechmann and Bowker, 2019;</ref><ref type="bibr" target="#b15">Crawford, 2021;</ref><ref type="bibr" target="#b28">Grosman and Reigeluth, 2019;</ref><ref type="bibr" target="#b41">Jaton, 2017</ref><ref type="bibr" target="#b42">Jaton, , 2019</ref><ref type="bibr" target="#b43">Jaton, , 2021;;</ref><ref type="bibr" target="#b68">Neyland, 2019)</ref>. By providing fine-grained depictions of ML algorithmic systems, these works have effectively acted as provisional STS Lab, University of Lausanne, Lausanne, Switzerland Corresponding author: Florian Jaton, STS Lab, University of Lausanne, Lausanne, Switzerland. Email: florian@florian-jaton.com countermeasures to the promotional rhetoric of AI over-enthusiasts and provided seminal means for greater governance of algorithmic systems <ref type="bibr" target="#b73">(Radfar, 2019;</ref><ref type="bibr" target="#b75">Shellenbarger, 2019)</ref>.</p><p>Among the issues these studies helped to bring to light, the problem of biases-unquestioned and contingent sociocultural habits that orientate output calculations-has certainly received the most attention. From the European Commission <ref type="bibr">(AI HLEG, 2019)</ref> to IBM <ref type="bibr" target="#b61">(McDade and Testman, 2019)</ref>, and McKinsey <ref type="bibr" target="#b76">(Silberg and Manyika, 2019)</ref>, the so-called AI bias problemgenerally associated with ethics and morality <ref type="bibr" target="#b66">(Mittelstadt et al., 2016)</ref>-is now one of the most frequently discussed topics. Although salutary in many respects, this rush toward the issue of AI bias has led to some confusion, prompting several authors to take steps toward clarifying the situation. What are biases? How can one spot them? Should they be stamped out? Under the threat of an AI ethics-washing <ref type="bibr" target="#b78">(Wagner, 2018)</ref> that allows powerful industrials to take refuge in intellectual vagueness, it seems more important than ever to analyze the elements at stake and specify the objects of debate. In the wake of recent efforts made by <ref type="bibr" target="#b3">Barocas et al. (2017)</ref> and <ref type="bibr" target="#b65">Mittelstadt (2019)</ref>, this paper contributes to providing conceptual tools capable of further refining the notion of bias and making it somewhat more operational.</p><p>To do so, this paper begins by introducing a positive view on biases. Instead of considering them as intrinsically deleterious, it appreciates biases as necessary, yet contingent, external referents. Often gathered in repositories called ground-truth datasets <ref type="bibr" target="#b28">(Grosman and Reigeluth, 2019;</ref><ref type="bibr" target="#b36">Henriksen and Bechmann, 2020;</ref><ref type="bibr" target="#b41">Jaton, 2017)</ref>, these constructed external referents operate as supervisors of learning processes: They define what needs to be learned and allow for performance measures. The paper then shows that these supervising biases concern a wide range of ML algorithms: As recent studies indicate, computer scientists have to confront-and be biased by-ground-truth datasets while shaping and implementing supervised and unsupervised ML algorithms. I then argue that these ground-truthing practices-that fundamentally involve establishing biases to enable learning procedures-can be described by their respective morality, here defined, in the wake of pragmatist philosopher William James, as the more or less accounted experience of hesitation when faced with "genuine options" <ref type="bibr" target="#b40">(James, 1912)</ref>-that is, choices to be made in the heat of the moment that engage different possible futures. I then stress three constitutive dimensions of this pragmatist morality, as far as ground-truthing practices are concerned: (I) the definition of the problem to be solved (problematization), (II) the identification of the data to be collected and set up (databasing), and (III) the qualification of the targets to be learned (labeling). I finally suggest that this three-dimensional (3D) conceptual space can be used to read ML algorithmic projects in terms of the morality of their respective and constitutive groundtruthing practices. Such techno-moral graphs may, in turn, serve as equipment for greater governance of AI systems. In the conclusion, I briefly expand on the outlined propositions.</p><p>Learning to be biased: On the centrality of ground truths</p><p>Examples of what <ref type="bibr" target="#b69">Noble (2018)</ref> coined algorithmic oppression abound: search engines that marginalize women <ref type="bibr" target="#b8">(Carpenter, 2015)</ref>; health prediction algorithms that consider Black patients riskier than White patients <ref type="bibr" target="#b70">(Obermeyer et al., 2019)</ref>; recommendation algorithms favoring violent, racist, and misogynist content <ref type="bibr" target="#b32">(Hao, 2019)</ref>; and crime prediction systems whose scores are more influenced by skin color than by criminal record entries <ref type="bibr" target="#b2">(Angwin et al., 2016)</ref>. These harmful biases must be fiercely criticized and combated. In order to do so, they must be identified through insightful statistical inquiries <ref type="bibr" target="#b14">(Courtland, 2018)</ref> but also, which tends to be taken for granted, through the affirmation of universal moral precepts such as fairness and equality. While such principles are not easy to describe rigorously <ref type="bibr">(Verma and Rubin, 2018)</ref>, it is still possible to roughly outline them and agree on the worldviews they suggest.</p><p>This moralism-in the sense of a confident attitude toward the moral values to be defended-is crucial today, not least in order to infuse political affections into the thematic universe of ML algorithms that, not so long ago, was still confined to mere technical considerations <ref type="bibr">(Jaton and Vinck, submitted)</ref>. However, framing the still-to-be-fought algorithmic oppression mainly in terms of bias (in singular) runs the risk of not being taken seriously, or at least, as suggested by <ref type="bibr" target="#b59">Manders-Huits and Zimmer (2009)</ref>, of not being invested with meaning by some of the people who may be very much concerned with the issue: computer scientists who work every day, in academia and industry, to shape new ML algorithmic tools.</p><p>To understand this risk of expert disbelief in ML bias as this notion is described in the critical literature on algorithms, it is needful to turn to another, older discourse that has progressively become quite inaudible outside the spheres of computer science. This classical and authoritative view comes from Tom Mitchell's pioneering work on statistical learning. As early as 1980, he showed that biases-understood as external and arbitrary sources of information 2 -are necessary for the inductive leap underlying any learning process. <ref type="bibr">Bowker and Star (2000: 111-123)</ref> call the bootstrapping problem led Mitchell to argue, in turn, that an unbiased learning algorithm would be senseless:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This specific instance of what</head><p>Although removing all biases from a generalization system may seem to be a desirable goal, in fact the result is nearly useless. An unbiased learning system's ability to classify new instances is no better than if it simply stored all the training instances and performed a lookup when asked to classify a subsequent instance. <ref type="bibr">(Mitchell, 1980: 2)</ref> In short, no biases, no learning: As Domingos recently summarized: "in ordinary life, bias is a pejorative word: preconceived notions are bad. However, in machine learning, preconceived notions are indispensable; you can't learn without them" <ref type="bibr">(Domingos, 2015: 64)</ref>.</p><p>Put crudely, then, biases are crucial for ML: Any classification task needs a referent that lies outside of the task in order to ground its classificatory principle. The centrality of ground-truth datasets (Figure <ref type="figure" target="#fig_0">1</ref>) for the training and evaluation of new ML algorithms is a striking illustration of this necessity: Without benchmarked databases that provide the referents of what ML algorithms must find <ref type="bibr" target="#b36">(Henriksen and Bechmann, 2020)</ref>, no learning operation is conceivable since there is no a priori indication of what is appropriate to learn. Removing all biases from ML algorithms-as it is sometimes suggested <ref type="bibr" target="#b25">(Gibney, 2020)</ref>-would therefore be tantamount to removing central parts of what allowed them to come into existence, namely the contingent, yet necessary, external referents that operate as their initial impetus. For the specific case of ML algorithms and systems, morality seems then obliged to deal with this state of affairs visible as soon as one walks through the door of a computer science laboratory <ref type="bibr" target="#b43">(Jaton, 2021)</ref>: A bias-free ML algorithm is an oxymoron.</p><p>The supervision of the "unsupervised": From ground truths to ground-truthing Before moving forward and further examining the issue of morality with regard to the ground truths that biasand enable-learning operations, it is important to look more precisely at another technical discussion related to ML algorithms. Papers and manuals on statistical learning methods are extremely numerous and varied. However, in this innovative and constantly changing nebula, one notion remains stable: that of supervision (and its opposite, unsupervision). With the possible exception of the category of "reinforcement learning"-which I will not discuss in this paper-computerized methods of calculation inferring classification or regression rules from aggregated data-what I refer to here as ML algorithms-are indeed divided, in the specialized literature, in two main families: supervised and unsupervised. This is a widely shared, standard statement: Supervised  <ref type="bibr" target="#b81">Yang et al. (2016)</ref>, sample from WIDER FACE ground-truth dataset. On the left, one among the 32,203 images of the publicly available dataset for face-detection research. In the middle, the face annotations for this specific image. Since each annotation belongs to the coordinate space of the digital image, it can be expressed by a set of four numerical values, the first two expressing the start position of the label along the x and y axes, the third one expressing the number of pixel wide, the fourth one expressing the number of pixels high. This numerical information, that correspond to the bounding boxes of the image on the right, were produced manually by one human annotator and cross-checked by two others <ref type="bibr">(Yang et al., 2016: 5527)</ref>. As such, they constitute the ground truth of the image with regard to face detection; they bias the input data in order to provide something to learn and formulate. The images and their labels can then be used to train supervised ML algorithms to recognize faces in photos, the groundtruth dataset operating as the list of the very best answers to such task.</p><p>algorithms for which an external supervisor "provides the correct values, and the parameters of a model are updated so that its output gets as close as possible to these desired outputs" are fundamentally different from unsupervised algorithms that do not require any supervisor and whose purpose is "to find the regularities in the input, to see what normally happens" <ref type="bibr">(Alpaydin, 2016: 112)</ref>. To put it in equivalent terms, while supervised algorithms need a ground-truth dataset gathering input data and manually constructed output targets in order to learn the predictive rules of computation, unsupervised algorithms rely only on input data to detect patterns and regularities.</p><p>For academic and industrial researchers who recognize this fundamental distinction (i.e., the vast majority), further development of unsupervised ML algorithms carries with it great hope since these algorithms do not depend, theoretically, on any external supervision of the input data. Substantial gains in time, resources, and purity are explicitly envisaged: Because unsupervised ML algorithms use only the information contained in their "raw" learning data, they would not be concerned with the formation of costly ground-truth datasets whose labels are tedious to produce and potentially influenced by the sociocultural habits of their human generators and curators. The sheer enthusiasm for unsupervised ML algorithms is evidenced in the now famous "cake analogy" proposed by Yann LeCun, one of the main initiators of convolutional neural networks and the winner of the prestigious Turing Award in 2018 (with Yoshua Bengio and Geoffrey Hinton), where "the bulk of the cake is unsupervised learning, the icing on the cake is supervised learning, and the cherry on the cake is reinforcement learning" (LeCun, 2016). 3  It would be incorrect to assert that this distinction between supervised and unsupervised ML algorithms is erroneous: When considered from a confined, theoretical perspective, unsupervised ML algorithms are not bounded to ground-truth datasets gathering input data and output targets, whereas supervised ML algorithms are. However, when considered "in the wild" <ref type="bibr" target="#b37">(Hutchins, 1995)</ref>, which is from a down-to-earth perspective, one realizes that the story is more intricate: It is indeed attested that ground truths and their concomitant referential practices do in fact impact, albeit in a less visible way, the practical shaping and use of ML algorithms presented as "unsupervised."</p><p>The first way to consider the subtle attachment of unsupervised ML algorithms to ground truths is simply to read recent award-winning papers presenting new unsupervised ML algorithms, such as <ref type="bibr" target="#b80">Wan et al. (2019)</ref>, <ref type="bibr" target="#b58">Lorenz et al. (2019)</ref>, <ref type="bibr" target="#b21">Fu et al. (2019), and</ref><ref type="bibr" target="#b55">Liu et al. (2019)</ref>. 4 Although these (quite) arbitrarily selected papers are all related to computer vision and image processing, each deals with a different problem: 3D hand pose estimation for <ref type="bibr">Wan et al., part-based</ref>  to convince readers of the relevance and efficiency of its unsupervised ML algorithm. Also, in the specific evidence-production regime of applied computer science, the acceptable way to do so is to rely on a ground-truth dataset-also called a benchmarked dataset-containing human-produced labels and operating as a measurement reference capable of generating statistical results (see Figure <ref type="figure" target="#fig_1">2</ref>). For each paper, the very topic of the computational operation is framed by, and dependent on, the availability of a ground truth previously constructed and used by other groups of researchers to develop and compare supervised ML algorithms. 5 It thus appears that even though these unsupervised ML algorithms do not rely upon any labeled ground truth for their learning tasks, they need available ground-truth datasets to attest to the significance of their results. Rather than a technical necessity, this is a practical imperative: Without referring to a ground truth operating as a yardstick between competing algorithms, the aforementioned researchers-but also, I believe, many others-cannot quantitatively measure the performances of their algorithms according to the standard statistical measures and cannot, therefore, make their algorithm exist within a searchable and quotable paper. This practical imperative is linked to the fact that unsupervised ML algorithms are not intended to remain theoretical: They are designed to be ultimately used and worked upon, which implies comparing them to benchmarked ground-truth datasets in order to show their relevance and efficiency. And if ground truths-together with their labels (and their biases)-are not necessary for the definition of the algorithms' learning functions, they remain essential to make them exist as devices producing valuable results.</p><p>Another reason why unsupervised ML algorithms remain attached to, and biased by, supervised "truths" can be understood by exploring the backstage of computer science work. Using the genre of autoethnography in an interdisciplinary data analysis laboratory, <ref type="bibr" target="#b5">Bechmann and Bowker (2019)</ref> documented the inconspicuous supervisory operations involved while applying an unsupervised algorithm (the Latent Dirichlet Allocation model Text2vec) to Facebook user data. As they made clear, an irremediable succession of arbitrary (but justifiable) choices were necessary to produce results that made sense by virtue of the research question, itself reworked as the multilateral relationships between the collected survey data, the provisional results produced by the algorithm, and the interpretive work unfold. Bechmann and Bowker convincingly showed, in turn, that in order to make the unsupervised algorithm operational, it was crucial to supervise its end-to-end deployment-that is, to refer to elements a priori external to the algorithmic process per se (e.g., their own values, doubts, disappointments, ambitions) in order to ground its correctness. As they sum it up: "a seemingly unsupervised model becomes extremely supervised due to classification work such as setting number of topics, cleaning data in a particular way with an a priori understanding of 'meaningful' clusters and interpreting clusters with parent classes manually" <ref type="bibr">(Bechmann and Bowker, 2019: 7)</ref>.</p><p>This second occurrence of biased supervision within the deployment of unsupervised ML algorithms suggests the need to somewhat extend the notion of ground truth. Indeed, in the case study of Bechmann and Bowker, a ground-truth dataset had not really been involved because the developers did not directly refer to assumedly correct, labeled responses listed in a benchmarked dataset as the authors of the imageprocessing papers mentioned earlier did. Yet, in effect, "truths" have been grounded-and biases established-because the researchers did refer to external sources of information (e.g., research questions, interpretations of results) that, in the end, attested to the correctness of the applied algorithm: Without their supervision work, the researchers could not make the "unsupervised" ML algorithm produce results useful to their research. Here, turning the notion of ground truth into a gerund seems somewhat necessary: Since the design and application of an unsupervised learning algorithm must, apparently, refer to elements that lie outside of its own functioning to effectively support and prove its efficiency and correctness, one should rather talk about ground-truthing rather than ground truths. If one sticks to the noun form, great are the risks to invisibilize the subtle grounding practices taking place during the design and implementation of seemingly unsupervised algorithms. At the risk of proposing a redundant expressionbut, sometimes, a little redundancy does not hurt-I propose calling ground-truthing practices the heterogeneous courses of actions aimed at attesting to the correctness of a computerized method of calculation. 6 Such practical biasing operations may range from the early problematization of an algorithmic project to the arbitrary selection of the relevant data and the actual construction, publication, and use of benchmarked ground-truth datasets (more on this later). Although these practices do not, by far, cover the whole process of algorithmic design-moments such as the mathematical characterization of the relationships between input data and output targets or the actual writing of computer code refer, for example, to qualitatively different processes (Jaton, 2021)-they nonetheless represent a non-negligible part of it. More than just setting up referential repositories, ground-truthing practices also support and make possible the very correctness of computerized methods of calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Morality as collective hesitation</head><p>Both supervised and unsupervised ML algorithms are attached to ground-truthing practices in order to be shaped, published, and applied in real-world situations. Without practical efforts to attest to ML algorithms' correctness and, therefore, temporarily move away from their technical functioning to establish biases and ground their efficiency, most ML algorithms could not exist and not a single one could be effectively used. Ground-truthing practices and the many biases they allow to be established are part and parcel with the constitution of ML algorithms: They contribute to making them designable, commensurable, and even, sometimes, efficient and useful.</p><p>By including this small realistic modality-ML algorithms need constructed and more or less contingent referential biases to show their correctness and come into existence-another landscape soon unfolds. Instead of irresistible ventures confidently inserting the depths of human cognition into digital devices, computer science industry, and, more particularly, its applied subdomains such as computer vision and image processing, start to appear radically fragile and uncertain. Indeed, a single change in the ground-truthing practices underlying the shaping and use of an ML algorithm could be enough to significantly modify its tenor. For the Facebook data analysis project considered by Bechmann and Bowker, a somewhat different problematization of the research effort would have led to quite different algorithmic results. The same is true for the work of the computer scientists mentioned above: A single change in the ground-truth datasets used to prove their results (e.g., a different question asked to the human annotators who labeled the collected data, different choices regarding the extraction and curation of the labels) would have led to the development of different unsupervised ML algorithms since they would have had to confront different ground truths. By stressing the ground-truthing practices underlying the shaping and use of ML algorithms, one highlights a trivial but often forgotten feature of computer science research and industry: It could be otherwise.</p><p>Hence, occasionally, a certain surprise on reading accounts of the shaping or application of ML algorithms. Even though what underlies the correctness of these models-which triumphantly permeate our daily lives-is often the result of contingent and arbitrary processes, few authors publicly admit to this constituent fragility and document the ins and outs of the alternatives that have been, at some point, available to them <ref type="bibr" target="#b23">(Geiger et al., 2020)</ref>. To put it in another, more philosophical way, while the ground-truthing work subtending ML algorithms is punctuated by irremediable choices, relatively few accounts explicitly attest to what pragmatist philosopher William <ref type="bibr" target="#b40">James (1912)</ref> classically called "genuine options"-that is, choices to be made in the heat of the moment that engage different possible futures or, in our case, different possible learning-enabling biases. What happens in these ground-truthing moments is indeed decisive, for as the biases implemented by computer experts will strongly frame what will later become, perhaps, a consulted ML model easily enrollable in broader corporate systems. 7 Could the morality of ML lie, at least in part, in these genuine options, moments when expert hands may shiver at the idea of grounding a "truth" that will then be reproduced, and thus promoted, computationally?</p><p>It is one of the many merits of James' philosophical work-and his contemporary interpretations <ref type="bibr" target="#b29">(Hache, 2011;</ref><ref type="bibr" target="#b34">Hennion and Monnin, 2020)</ref>-to have detected the moral tonality of these moments of hesitation where actors are attentive to the fragility of what they are accomplishing. Contrary to the Kantian tradition which considers morality as the result of a judgment subtended by a universal law, 8 the pragmatist tradition considers morality as the temporary experience of, and inquiry into, concerns and scruples. The turning around is thus complete: Instead of considering morality as compliance with a transcendent norm, morality is considered as the follow-up on the spark of a genuine option, triggering in turn an investigation of the ins and outs of a situation of uncertainty. During pragmatist moral experiences, what was initially considered a simple means (e.g., a crowdsourcing company, a ground-truth dataset, a research direction, an evaluation metrics) is transformed, temporarily, into an end whose trajectory depends on many other intertwined entities. And it is the uncertain exploration, long or short, of the connections between these entities that constitutes the specific signature of morality.</p><p>Considering morality as what is happening when there is an investigation on the fragilities and uncertainties of a genuine option that sparks may sound odd at first, but it effectively addresses a mundane, increasingly common experience: that car I drive, that meat I grill, or that search engine I use; these a priori unproblematic entities become frantically animated as my scruple sets in and my investigation unfolds. That car soon connects needs for mobility with workers in Northern France and birds stuck in oil spills; that meat soon connects clich e summer partying with traceability networks and fertilizers for fodder fields; and that search engine soon connects urgent desires for access to certified references with new forms of alienations subtending digital capitalism: As soon as a scrupulous doubt as to a means turns it into an end, a relational experience is set in motion that brings about many intertwined human and nonhuman entities. As Hache pointed out, this problematization "engages a conception of relational morality in which one cannot be moral on one's own" <ref type="bibr">(Hache, 2011: 52</ref>. My translation); the intermingling operated during the more or less long moments of hesitant investigation turns moral experiences into collective enterprises.</p><p>From this, it follows that morality-in its pragmatist understanding-can blossom in some settings and wither away in some others. Certain arrangements can favor great moral development by valuing the expression of doubt and the hesitant exploration of scruples, to the point of even instituting them-sometimes-as a working habit. 9 Conversely, other arrangements can, voluntarily or not, repress moral development, thus making what Latour calls the "emission of morality" <ref type="bibr">(Latour, 2012: 454)</ref> inaudible. In these constricted settings, scruples are stifled; hesitations as to the distinction between means and ends are ignored; genuine options are pale glimmers, practically invisible and incapable of suggesting anxious inquiries.</p><p>Pragmatist-inspired morality is thus what is happening when there is a collective exploration of the fragilities and uncertainties of a genuine option that sparks. During moral moments-whose development can be sustained or repressed-means are temporarily turned into problematic ends through concerned and hesitant collective inquiries. From there, if we return to ML algorithms and take the point of view of those who work every day to build new robust and innovative ones (who may be different from those who talk about ML and AI during keynotes and distinguished lectures), two opposite ways of experiencing groundtruthing practices emerge. Either ignore (or keep quiet) the genuine options that dot ground-truthing practices and consider their constituent elements as unproblematic means for the completion of the algorithmic project; or, at the other end of the spectrum, be systematically sensitive to the scruples and uncertainties. Variable intensities are, of course, conceivable, but it seems a priori fair to posit that ML designers go through differentiated moral experiences that could be summarized as follows: being more or less eager (or encouraged) to confront and unfold the fragility of ground-truthing practices; being more or less eager (or encouraged) to respond to what they are bound to while building referential bases for the proper shaping and deployment of ML algorithms.</p><p>By virtue of the perspective adopted in this paper, ground-truthing practices (and the biases they establish) contributing to ML algorithmic projects are then not always morally equivalent: Some are more sensitive to the irruption of genuine options and the exploration of their underlying uncertainties than others (see Figures <ref type="figure">3</ref> and<ref type="figure" target="#fig_3">4</ref>). Also, without suspecting anyone of negligence, one may consider that many current ML projects are not especially moral in the sense defined here. There are numerous reasons for this, and the race for valuable innovation and publication is certainly part of the phenomenon <ref type="bibr" target="#b63">(Mirowski, 2011)</ref>. However, the sheer act of attributing the adjective "unsupervised" to highly supervised-and thus biased-algorithms may illustrate a lack of sensitivity to, and emphasis on, the hesitation between the means and ends of many contemporary ML developments <ref type="bibr" target="#b23">(Geiger et al., 2020)</ref>.</p><p>However, more and more organizations are beginning to show, through their actions, that the moral issue of algorithms is an integral part of their concerns. By opening their doors to sociologists, philosophers, journalists, anthropologists, or ethnographers and, in particular, encouraging them to document the practices by which "truths" are instituted in order to establish the correctness of algorithms being shaped and used, the data analysis laboratory mentioned by <ref type="bibr" target="#b5">Bechmann and Bowker (2019)</ref>, the image-processing laboratory followed by <ref type="bibr" target="#b41">Jaton (2017</ref><ref type="bibr" target="#b43">Jaton ( , 2021))</ref>, the European automatic surveillance projects studied by <ref type="bibr" target="#b28">Grosman and Reigeluth (2019)</ref> and <ref type="bibr" target="#b68">Neyland (2019)</ref>, or the Scandinavian AI firm investigated by <ref type="bibr" target="#b36">Henriksen and Bechmann (2020)</ref> show, for example, a genuine desire for morality, understood as a propensity to make more explicit, and therefore real, the exploratory hesitations and doubts contributing to algorithmic projects. The current situation seems then to be quite mixed: Whereas many algorithm-related organizations, especially the most powerful ones, are frankly reluctant to make hesitations and uncertainties visible and thus favor the modernist path of inevitable mastery <ref type="bibr" target="#b71">(Pasquale, 2016)</ref>, others, fewer in number but nevertheless increasingly present, are ready to make the morality of the devices they build positive. By inviting lay actors to co-investigate with computer science professionals on algorithmic work cases, these ecological institutions-in the sense of institutions sensitive to networks of interdependencies <ref type="bibr" target="#b51">(Latour, 2017</ref>)-agree to be accountable for some of their actions and, thus, accept to become more response-able. This is something important to point out: In computer science and industry, morality is nowadays actively opposed but also supported (albeit still tentatively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Toward techno-moral graphs: Problems, data, and labels</head><p>If we accept to consider morality as the act of responding to what <ref type="bibr">Latour (2004: 216)</ref> calls "the generalized revolt of means" by embarking on collective investigations of genuine options-and thus distinguish it from moralism understood as the important, yet sometimes limited, injunction to observe universal moral precepts-it still remains, in our case, to somewhat specify the environment in which this morality can be deployed. At this point, the term "ground-truthing practices" remains too vague to hope to detect moral Figure <ref type="figure">3</ref>. Schematics of ground-truthing practices sensitive to encounters with genuine options. Let us imagine ground-truthing courses of action using means (e.g., benchmarked ground-truth datasets, evaluation metrics) as part of an ML algorithmic project. When doubts arise regarding a means (genuine option 1), this scrupulous hesitation temporarily shifts the project to exploring the issues underlying the option, considering and, eventually, rejecting (or embracing) sets of possible futures (vertical dotted arrows). Once the investigation has been provisionally completed-making the end become, temporarily, an acceptable means-the design decision as to the genuine option moves the project forward to, potentially, another genuine option (genuine option 2) whose fragility triggers, in turn, another collective exploration of the whys and wherefores of the uncertain situation.  differentials with regard to the contingent, yet crucial, biases that make ML algorithms possible and usable. How can one see more clearly in this imbroglio that I call "ground-truthing practices"?</p><p>One may start by pointing out something that is trivial in hindsight: The problem an ML algorithm solves is not a priori given; it is the result of problematization practices aimed at establishing the terms of a problem that can be solved computationally. The institutional, and contingent, definition of algorithms as "computerized problem-solving methods" may have contributed to putting aside the basic fact that problems that aim to be solved by algorithms are temporary results of processes engaging habits, desires, skills, and values <ref type="bibr">(Jaton and Vinck, submitted)</ref>. As Lehr and Ohm nicely summarized, for ML algorithms whose tasks are to predict and estimate something, "the first step of any analysis is to define what that something should be and how it should be measured" <ref type="bibr">(Lehr and Ohm, 2017: 672-673</ref>. Emphasis in the original).</p><p>A first dimension of ground-truthing practices may then refer to the courses of action that participate in problematizing a state of affairs. Here, the external referents, or biases, to be defined are the terms of the problem the algorithm will have to solve. The imageprocessing project followed by Jaton ( <ref type="formula">2017</ref>) is illustrative in this respect. In order to launch their project of a new image-processing algorithm for saliency detection, the computer scientists had to start by critically examining the state-of-the-art literature, notably by equipping themselves with authoritative-and highly indexed-papers in philosophy and cognitive science, and by imagining new industrial applications based on their criticism. I shall group under the term "problematization" this type of practical work that can take many different forms but still consists, ultimately, in making a situation problematic and presenting the would-be algorithm as a solution potentially generating positive differences.</p><p>A second dimension specific to ground-truthing practices, and the biases they contribute to establishing, can be detected with another trivial observation: Algorithms, especially ML ones, need sets of data. This aspect of the preparatory work required for the shaping and use of ML algorithms was made particularly visible in recent years by the (temporary) advent of the term "Big Data" and, simultaneously, by more or less successful attempts to enforce data privacy. Unsurprisingly, then, it is in the fields of law and ethics that one finds the most refined explorations of the issues related to the massive online collection and organization of digital data to be transformed into "raw" materials for the shaping of ML algorithms and systems <ref type="bibr" target="#b4">(Barocas and Selbst, 2016;</ref><ref type="bibr" target="#b16">Custers et al., 2012;</ref><ref type="bibr" target="#b54">Lehr and Ohm, 2017)</ref>. Building upon these important works to further specify the heterogeneity of ground-truthing practices, I shall call "databasing" the actual work of collecting, compiling, organizing, and cleaning the data to be used for the shaping and/ or training of new ML algorithms. As its name suggests, this particular dimension of ground-truthing practices-which often takes place in parallel with problematization activities and impacts on them-cannot be reduced to the collection of data alone. It also includes choices and actions contributing to the aggregation, probing, organization, and cleaning-in short, the setting up-of what may be called at some point the "raw" data <ref type="bibr" target="#b26">(Gitelman, 2013;</ref><ref type="bibr" target="#b44">Jaton and Vinck, 2016)</ref>.</p><p>Finally, a third dimension specific to groundtruthing practices is to be found in the categories or labels (or output targets) that are superimposed on the collected "raw" input data by means of more or less standardized devices and procedures. As summarized by Grosman and Reigeluth, this refers to the "ground truth" part of the term "ground-truth dataset": the categories or labels which humans-for example, domain experts, computer scientists or Amazon turkers-have attributed to each sequence. It supplies the system with answers to the problem: the algorithm now has an external check for assessing the correctness of its classification. <ref type="bibr">(Grosman and Reigeluth, 2019: 3)</ref> The increasing availability of crowdsourcing services proposed by companies such as Amazon (via Amazon Mechanical Turk) or ClickWorker since 2010 had a considerable impact on the production capacity of labels and, as a result, on the proliferation of algorithms capable of retrieving and thus reproducing (and promoting) these labels. 10 Consequently, more than being strictly about computer science research, the production of labels also had, and has, a wider socioeconomic impact-the often worrying ramifications of which have been well studied by <ref type="bibr" target="#b27">Gray and Suri (2019)</ref> and <ref type="bibr" target="#b9">Casilli (2019)</ref>. Here, I shall use "labeling" as an umbrella term to designate the heterogeneous, but assignable, practices involved in defining, organizing, remunerating, and, sometimes, refining the labels that provide ML algorithms-supervised and unsupervised-with answers to the problems they try to solve. While this axis of ground-truthing practices might be, for the time being, the one with the most obvious ramifications to global socioeconomic issues, it does not unfold independently from the other two axes. Indeed, as suggested in <ref type="bibr">Jaton (2021: 31-86)</ref>, some algorithmic projects may start to organize the production of labels once their problem has been defined and their data collected and set up, other projects may start by considering the facilities available for the production of labels in order to define the terms of a problem in a different way, and other projects may use available data to define a problem and the labels that can be used to solve it. Although referring to different practices, the three axes-problematization, databasing, and labeling-echo each other in ways that are specific to each individual ML endeavour.</p><p>If we combine the elements presented in this section, we find ourselves with, at least, three dimensions-or axes-on which, schematically, ground-truthing practices contributing to ML projects can be represented: a first axis for the problematization practices (e.g., criticizing previous research results, capitalizing on past achievements), a second axis for the databasing practices (e.g., web scrapping, distribution analyses), and a third axis for the labeling practices (e.g., designing a crowdsourcing task, implementing an available benchmarked ground truth). And the whole of this space, now delineated, constitutes the bulk of groundtruthing practices that are crucial for the shaping and use of ML algorithms, whether supervised or unsupervised (see Figure <ref type="figure">5</ref>). If we now include the somewhat speculative (yet informed) elements of moral philosophy presented in the previous section, each axis of this 3D ground-truthing space becomes staggered by potential genuine options that, themselves, refer to potential explorative and collective hesitations between means and ends (Figure <ref type="figure">6</ref>).</p><p>From there, the theoretical space of ground-truthing practices becomes a visual and conceptual space on which specific courses of action can eventually be reported. This scriptural technology, rudimentary but refinable, could then support maps differentiating ML algorithm projects with regard to their ground-truthing practices (see Figure <ref type="figure">7</ref>). These techno-moral graphsthat still need to be put to the test-would be a way to visualize the moral narratives of the ground-truthing practices contributing to ML projects-that is, Figure <ref type="figure">5</ref>. Schematics of the three dimensions of groundtruthing practices. On the top, the "problematization" dimension refers to the practices partaking the definition of the terms of a solvable problem. On the right, the "databasing" dimension refers to the practices partaking the aggregation, probing, organization, and cleaning of the data to be used for the shaping and/ or training of a new algorithm. On the left, the "labeling" dimension refers to practices partaking the definition, organization, collection, and access to the labels that provide the new supervised or unsupervised ML algorithm with answers to the problem it should solve. Figure <ref type="figure">6</ref>. Schematics of the three dimensions of groundtruthing practices when staggered by the genuine options that, potentially, spot their deployment. Each intersection between lines and axes corresponds to a potential genuine option partaking the deployment of problematization, databasing, or labeling actions.</p><p>Figure <ref type="figure">7</ref>. Techno-moral graph of three hypothetical ML projects. If, by convention, each encounter with a genuine option counts as 1, the addition of these attested meetings/explorations allows to report a value on one (or more) of the three axes P (problematization), D (databasing), and L (labeling). The pragmatist morality of each ML project-as far as its ground-truthing practices are concerned-could then be summarized by its more or less extended map on the coordinate system. The more accounted (and available) explorative hesitations on each of the axes (small black dots on the axes), the more morality.</p><p>narratives that are all the more voluminous as the morality maps of their related projects are large. Similar to the sociotechnical graphs introduced by <ref type="bibr" target="#b52">Latour et al. (1992)</ref>, techno-moral graphs would have no value by themselves: They could only make sense if they point to already existing documents and reports, notably, and above all, those accounting for the collective investigations underlying genuine options. This scriptural device, for the moment quite speculative, may operate as a reflexive instrument whose main aim like that of any other instrument, is to get rid of most of the initial information, while outlining the features that are deemed relevant to our inquiry, <ref type="bibr">[and]</ref> offer a quick and easy comparative basis for many narratives coming from many sources. <ref type="bibr">(Latour et al., 1992: 37)</ref> In short, techno-moral graphs would be a way, among other possible ones, to visualize, make explicit, and compare some of the constitutive biases of ML algorithms.</p><p>Despite the apparent simplicity of these technomoral graphs-they are, after all, only a superficial way of visualizing the quantities of assignable hesitations and scruples that have dotted the ground-truthing practices underlying specific ML projects-they do point to deep issues. First, techno-moral graphs suggest that, for the specific case of ML algorithms-entities that easily pervade our lives-morality must be supported by accessible inscriptions and writings: Without a tangible record of the emergence of a genuine option and its correlated exploration, there is no way to further attest to its existence. This denotes, in turn, the power of inscriptions and their centrality in the composition of the collective world <ref type="bibr">(Jaton, 2021: 12-17)</ref>. Second, techno-moral graphs suggest that morality can also be thought of as a quantifiable continuum: when there are more accounted scruples about means, there is more morality (i.e., the surface of the map is larger). While the consultation of the accounts reporting on the collective explorations would be crucial to assess the seriousness of the enterprise (the only way to ensure that the graph is the expression of thoughtful moral concerns), techno-moral graphs would also give a rough indication about the number of genuine options explored. If this somewhat personal operationalization of James' pragmatist morality may seem fussy, even bureaucratic, it has the merit of giving the graphs a potential binding effect: An ML algorithm could be considered all the more moral as it has gone through many explored, and accounted, genuine options. The graphs may then become (costly) moral backings capable of serving, eventually, as a basis for subsequent evaluations. In that sense, if, in conjunction with the development of ML-related projects, technomoral graphs were also required (and this would entail dedicated moral secretaries), the biases that are constitutive of ML algorithms would finally start to be assessed instead of being repressed.</p><p>Discussion and conclusion: ML governance equipped with assessed biases?</p><p>In a recent paper, <ref type="bibr" target="#b46">Jobin et al. (2019)</ref> identified 84 public-private initiatives describing sets of principles to guide the moral/ethical development of ML, increasingly affiliated with AI. While this principled approach is certainly important in its ability to, sometimes, evoke political affects among non-expert publics, it is not sufficient to make effective differences. With regard to ML, moralism may establish a horizon to be reached but fails to enforce clear procedures. Worse, the active participation of AI companies in these high-level ethical and moral issues contributes to the ambient vagueness while also encouraging "policy-makers with a reason not to pursue new regulation" <ref type="bibr">(Mittelstadt, 2019: 501)</ref>. It is, in turn, difficult to be satisfied with the current situation: If one adheres to the ideals contained in the principled approach to ML and AI ethics, one has to admit that this moralism, on its own, does not have the means to achieve its ambitions. It still needs to be supported by new devices, procedures, and habits that have yet to be invented.</p><p>In this theoretical paper, I proposed a moral device based on the notion of bias and, more broadly, on what I called ground-truthing practices. I started by showing that biases should not be seen as a priori negative: According to Tom Mitchell's pioneering work on statistical learning, biases are necessary to define learning functions. Asking an ML algorithm to be bias-free would be tantamount to asking a tree to have no roots: a genuine contradictory injunction that has no chance of engaging binding mechanisms. I then considered ground-truth datasets to be repositories of biases that are central to the development of ML algorithms. I first proposed that, contrary to what is sometimes asserted in the specialized literature, these referential databases-and their underlying design practices that I call ground-truthing practices-contribute to the development of supervised and unsupervised ML algorithms. In order to come into existence and be used in real-world situations, ML algorithms depend indeed on biases that are the results of assignable practices. However, these practices can be more or less moral depending on their ability to make themselves sensitive to what William <ref type="bibr" target="#b40">James (1912)</ref> called genuine options: moments of doubt about the consequence of an action that is necessary, irremediable, and imminent. The morality of ML processes may then be coextensive with the exploration of their radical fragility: When there are more scrupulous doubts about the practices for defining the problem to be solved, about the data to be set up, and about the targets to be learned, there is more morality. I then suggested that these three practical axes that specify and delimit ground-truthing practices-problematization, databasing, and labeling-could be used as a scriptural space capable of hosting what I call techno-moral graphs: instruments for reporting and comparing the quantity of moral operations that took place during the grounding of ML-related projects. These graphs, like any other graph, would not be useful by themselves but by the many elements they compile and format. The technomoral graph of an ML project would permit the visualization of the moral space of its ground-truthing part and-together with the qualitative consideration of the documents that each point incrementing the graph refer to-ensure that alternatives have indeed been the object of collective investigations. In that sense, it is a whole ecology of texts and documentation that would be summarized in techno-moral graphs that could not, obviously, exist on their own.</p><p>To imagine that each ML-related project proposes, in addition to its inner workings and performances, a techno-moral graph referring to the accessible accounts of the doubts and hesitations that occurred in its ground-truthing practices may seem utopian, at best. Devoting care and time to exposing the essential fragilities of ML algorithms and systems is not, by far, the priority of the actors involved in this industry whose products increasingly, and triumphantly, contribute to irrigating our daily lives. However, if biases are indeed constitutive of ML (which remains to be further demonstrated by in situ ethnographic studies), the current invisibility of biases must also be the result of a work of purification <ref type="bibr">(Latour, 1987: 45-62)</ref> aimed at distinguishing them from the algorithms and systems they underlie. From there, integrating more morality into MLshaping practices might be a matter of mere substitution: In place of the many efforts to make the biases underlying ML algorithms and systems invisible, one may think about valuing other efforts, such as those that would make biases visible and consultable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notes</head><p>1. STS are a subfield of social sciences that aims to document the co-construction of science, technology, and the collective world. What connects the practitioners of this heterogeneous research community is the conviction that science is not only the expression of a logical empiricism, that knowledge of the world does not preexist, and that scientific and technological truths are dependent on collective arrangements, instrumentations, and dynamics <ref type="bibr" target="#b17">(Dear and Jasanoff, 2010)</ref>. I consider myself fully part of this research community. 2. More precisely, Mitchell describes bias as "any basis for choosing one generalization over another, other than strict consistency with the observed training instances" <ref type="bibr">(Mitchell, 1980: 1)</ref>. 3. At the 2019 International Solid-State Circuits Conference <ref type="bibr" target="#b39">(ISSCC videos, 2019)</ref>, LeCun refined his "cake analogy."</p><p>The bulk of the cake is now self-supervision, a subcategory of unsupervised learning where the data provides its own supervision. This method makes convolutional neural networks independent from labels during their learning operations. 4. I selected these articles because they were all finalists for the "best paper award" of the 2019 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). CVPR is one of the most prestigious and selective conferences in computer vision and image processing. For the 2019 edition, among the 5160 papers submitted, 1294 were accepted (25%) and 45 (0.87%) ended up being part of the final best paper award list.  <ref type="bibr" target="#b62">Menze and Geiger (2015)</ref>. 6. In a recent paper, <ref type="bibr" target="#b36">Henriksen and Bechmann (2020)</ref> proposed to call such grounding practices "truth practices." To me, this term is completely equivalent to "groundtruthing." However, there are two reasons why I prefer to use this somewhat complicated (and not very phonic) terminology: (1) It is a vernacular expression: "groundtruthing" is sometimes used in the field of applied computing to designate the action of defining external referents to support an algorithmic process.</p><p>(2) Its tends to limit metaphysical speculation: the expression "groundtruthing" somewhat hides the philosophically very loaded term "truth." 7. In a recent TechCrunch article <ref type="bibr" target="#b12">(Constine, 2019)</ref>, Jordan Fisher-chief executive officer of Standard Cognition, a start-up that specializes in image recognition for autonomous checkout-talked about the enrolment of ML publications for industrial purposes: "It's the wild westapplying cutting-edge, state-of-the-art machine learning research that's hot off the press. We read papers then implement it weeks after it's published, putting the ideas out into the wild and making them productionworthy." 8. Moral experiences, according to Kant, only make sense in so far as they fall under the jurisdiction of a universal and necessary law. And the categorical imperative-formulated in <ref type="bibr" target="#b47">Kant (1998</ref><ref type="bibr" target="#b47">Kant ( [1785]]</ref>)-is the finite version of the universal law that is applicable by us, finite humans, to our ordinary actions. 9. On the possibility to build habits around the exploration of genuine options, see the ethnographic work of <ref type="bibr" target="#b30">Haeringer and Pecqueux (2020)</ref> on the space for dialogue "Parlons-en" in Grenoble, France. 10. With its millions of annotated images, the ground-truth dataset ImageNet is certainly the most illustrative example of the correlation between advances in computer science research and the construction and dissemination of ground-truth datasets. For a (quick) history of the formation of ImageNet, see <ref type="bibr">Gray and Suri (2019: 6-8)</ref> as well as <ref type="bibr" target="#b24">Gershgorn (2017)</ref> and <ref type="bibr" target="#b60">Markoff (2012)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Taken from<ref type="bibr" target="#b81">Yang et al. (2016)</ref>, sample from WIDER FACE ground-truth dataset. On the left, one among the 32,203 images of the publicly available dataset for face-detection research. In the middle, the face annotations for this specific image. Since each annotation belongs to the coordinate space of the digital image, it can be expressed by a set of four numerical values, the first two expressing the start position of the label along the x and y axes, the third one expressing the number of pixel wide, the fourth one expressing the number of pixels high. This numerical information, that correspond to the bounding boxes of the image on the right, were produced manually by one human annotator and cross-checked by two others(Yang et al., 2016: 5527). As such, they constitute the ground truth of the image with regard to face detection; they bias the input data in order to provide something to learn and formulate. The images and their labels can then be used to train supervised ML algorithms to recognize faces in photos, the groundtruth dataset operating as the list of the very best answers to such task.</figDesc><graphic url="image-8.png" coords="3,75,77,563,13,141,03,52,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure2. Two evaluations ofLiu et al.'s (2019)  unsupervised ML algorithm (ours). On top, qualitative evaluations of Liu et al.'s algorithm with respect to Sintel<ref type="bibr" target="#b7">(Butler et al., 2012)</ref> and KITTI<ref type="bibr" target="#b22">(Geiger et al., 2012;</ref><ref type="bibr" target="#b62">Menze and Geiger, 2015)</ref> ground-truth datasets for flow estimation. On bottom, quantitative comparisons between the performances of Liu et al.'s algorithm (ours) and previouslypublished algorithms with respect to Sintel and KITTI ground-truth datasets. The main performance metrics for these datasets is the average endpoint error: the overall comparison between the estimated optical flow vectors provided by the algorithm and those provided by the ground truth. KITTI 2012 and its augmented version KITTI 2015 also include the percentage of erroneous pixels of the algorithms' estimations. Except on the Sintel Clean test set, Liu et al.'s unsupervised algorithm outperforms all the others. The outperforming results are highlighted in bold. Source: Taken from Liu et al. (2019: 4-5), reproduced with the permission of the IEEE, 31 March 2021, 5039350523845, Pengpeng Liu, June 2019.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure4. Schematics of ground-truthing practices not sensitive to encounters with genuine options. In this case, the groundtruthing courses of action have not encountered/made appear any genuine options. No form of hesitation has turned a means into an end. The progress is straight-line and does not expressively take into account alternative futures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>5. More precisely, to test their unsupervised 3D hand pose estimator,<ref type="bibr" target="#b80">Wan et al. (2019)</ref> relied upon the ground truth NYU Test Set initially proposed by<ref type="bibr" target="#b77">Tompson et al. (2014)</ref>. To evaluate their algorithm for part-based disentangling of object shape,<ref type="bibr" target="#b58">Lorenz et al. (2019)</ref> used CelebA by Liu et al. (2015), Cat Head by Zhang et al. (2008), CUB-200-2011 by Wah et al. (2011), BBC Pose by Charles et al. (2013), Human3.6M by Ionescu et al. (2014), Penn Action by Zhang et al. (2013), Dogs Run (self-made), and Deep Fashion by Liu et al. (2016). To evaluate their unsupervised domain-mapping algorithm, Fu et al. (2019) used Cityscape by Cordts et al. (2016), MNIST initially developed by LeCun, Cortes, and Burges and further publicized by Deng (2012), and SVHN by Netzer et al. (2011). Finally, to evaluate and compare their self-supervised algorithm for optimal flow, Liu et al. (2019) used MPI Sintel developed by Butler et al. (2012), KITTI 2012 by Geiger et al. (2012), and KITTI 2015 by</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Jaton</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>I gratefully acknowledge valuable comments provided on earlier drafts by the editors and the anonymous reviewers of this journal. I also would like to express special thanks to <rs type="person">J er emie Garrigues</rs>, <rs type="person">Nils Graber</rs>, <rs type="person">Francesco Panese</rs>, <rs type="person">Jessica Pidoux</rs>, <rs type="person">Loic Riom</rs>, <rs type="person">Tanja Schneider</rs>, <rs type="person">Tatiana Smirnova</rs>, <rs type="person">Philippe Sormani</rs>, <rs type="person">L ea Stiefel</rs>, and <rs type="person">Dominique Vinck</rs> who gave me insightful suggestions after the first round of peer review. All mistakes and low passes remain, of course, mine.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was supported by <rs type="funder">Schweizerischer Nationalfonds zur Fâ‚¬ orderung der Wissenschaftlichen Forschung</rs> (<rs type="grantNumber">P2LAP1 184113</rs> and Sinergia 180350).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HSmMmAT">
					<idno type="grant-number">P2LAP1 184113</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of conflicting interests</head><p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ethics guidelines for trustworthy AI</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>High-Level</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Expert</forename><surname>Group -Aihleg</surname></persName>
		</author>
		<ptr target="https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai" />
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<date type="published" when="2019-04-08">2019. 8 April. May 2019</date>
			<pubPlace>Brussels</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Alpaydin</surname></persName>
		</author>
		<title level="m">Machine Learning: The New AI</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Angwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattu</surname></persName>
		</author>
		<ptr target="www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" />
		<title level="m">Machine bias. ProPublica, 23 May</title>
		<imprint>
			<date type="published" when="2016-06-10">2016. 10 June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fairness in machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<ptr target="https://fairmlbook.org/tutorial1.html" />
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-05">2017. 2017. May 2019</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="4" to="9" />
		</imprint>
	</monogr>
	<note>December. Video available at</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Big data&apos;s disparate impact</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Selbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">California Law Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="671" to="732" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised by any other name: Hidden layers of knowledge production in artificial intelligence on social media</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Bowker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">205395171881956</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Bowker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Star</forename><surname>Sl</surname></persName>
		</author>
		<title level="m">Sorting Things Out: Classification and Its Consequences</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Gb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="611" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Google&apos;s algorithm shows prestigious job ads to men, but not to women</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carpenter</surname></persName>
		</author>
		<ptr target="www.independent.co.uk/life-style/gadgets-and-tech/news/googles-algorithm-shows-prestigious-job-ads-to-men-but-not-to-women-10372166.html" />
	</analytic>
	<monogr>
		<title level="m">The Independent, 7 July</title>
		<imprint>
			<date type="published" when="2015-06-10">2015. 10 June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">En Attendant Les Robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Casilli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Le Seuil</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain adaptation for upper body pose tracking in signed TV broadcasts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Magee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British machine vision conference</title>
		<meeting>the British machine vision conference<address><addrLine>Bristol, UK; Norwich, UK</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2013-09">2013. September</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">How surveillance cameras could be weaponized with A.I. The New York Times</title>
		<author>
			<persName><surname>Chokshi</surname></persName>
		</author>
		<ptr target="www.nytimes.com/2019/06/13/us/aclu-surveillance-artificial-intelligence.html" />
		<imprint>
			<date type="published" when="2019-06">2019. June. July 2019</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">To automate bigger stores than Amazon, standard cognition buys Explorer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Constine</surname></persName>
		</author>
		<ptr target="http://social.techcrunch.com/2019/01/07/autonomous-checkout/" />
		<imprint>
			<date type="published" when="2019-01">2019. January. July 2019</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Las Vegas, NV; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016-06-26">2016. 26 June-1 July</date>
			<biblScope unit="page" from="3212" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bias detectives: The researchers striving to make algorithms fair</title>
		<author>
			<persName><forename type="first">R</forename><surname>Courtland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">558</biblScope>
			<biblScope unit="issue">7710</biblScope>
			<biblScope unit="page" from="357" to="360" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Yale University Press</publisher>
			<pubPlace>New Haven</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Discrimination and Privacy in the Information Society: Data Mining and Profiling in Large Databases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Custers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schermer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dismantling boundaries in science and technology studies</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jasanoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Isis; An International Review Devoted to the History of Science and Its Cultural Influences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="759" to="774" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The MNIST database of handwritten digit images for machine learning research</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>best of the web</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="141" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Basic Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Geometry-consistent generative adversarial networks for one-sided unsupervised domain mapping</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="2422" to="2431" />
			<date type="published" when="2019-06">2019. 2019. June</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>Long Beach, CA; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Are We ready for autonomous driving? The KITTI vision benchmark suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Providence, RI; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2012-06">2012. June</date>
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on fairness, accountability, and transparency</title>
		<meeting>the 2020 conference on fairness, accountability, and transparency<address><addrLine>Barcelona, Spain; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2020">2020. 27-30 January</date>
			<biblScope unit="page" from="325" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The Data That Transformed AI Research-and Possibly the World. Quartz</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gershgorn</surname></persName>
		</author>
		<ptr target="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/" />
		<imprint>
			<date type="published" when="2017-07-26">2017. July 26. 10 July 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The battle for ethical AI at the world&apos;s biggest machine-learning conference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gibney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">577</biblScope>
			<biblScope unit="issue">7792</biblScope>
			<biblScope unit="page" from="609" to="609" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Raw Data&apos; Is an Oxymoron</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gitelman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Houghton</publisher>
			<pubPlace>Boston; Mifflin Harcourt</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Perspectives on algorithmic normativities: Engineers, objects, activities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grosman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reigeluth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2053951719858742</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Hache</surname></persName>
		</author>
		<title level="m">Ce a`Quoi Nous Tenons. Propositions Pour Une E Â´cologie Pragmatique</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<publisher>La D ecouverte</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">La vuln erabilit e comme ouverture a`la contingence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Haeringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pecqueux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Deux enqueË†tes situ ees. SociologieS [Online</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Du pragmatisme au m eliorisme radical</title>
		<author>
			<persName><surname>Dossiers</surname></persName>
		</author>
		<ptr target="http://journals.openedition.org/sociologies/14011" />
		<imprint>
			<date type="published" when="2019-05">May 2, 2020. May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">YouTube is experimenting with ways to make its algorithm even more addictive</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hao</surname></persName>
		</author>
		<ptr target="www.technologyreview.com/2019/09/27/132829/youtube-algorithm-gets-more-addictive/" />
	</analytic>
	<monogr>
		<title level="j">MIT Technology Review</title>
		<imprint>
			<date type="published" when="2019-09-27">2019. 27 September. 10 June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Applied machine learning at Facebook: A datacenter infrastructure perspective</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international symposium on high performance computer architecture</title>
		<meeting><address><addrLine>Vienna, Austria; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2018">2018. 2018. 24-28 February</date>
			<biblScope unit="page" from="620" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Du pragmatisme au m eliorisme radical : enqueË†ter dans un monde ouvert, prendre acte de ses fragilit es, consid erer la possibilit e des catastrophes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hennion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monnin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Introduction au Dossier. SociologieS [Online</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Du pragmatisme au m eliorisme radical</title>
		<author>
			<persName><surname>Dossiers</surname></persName>
		</author>
		<ptr target="http://journals.open-edition.org/sociologies/13931" />
		<imprint>
			<date type="published" when="2019-05">May 2, 2020. May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Building truths in AI: Making predictive algorithms doable in healthcare</title>
		<author>
			<persName><forename type="first">A</forename><surname>Henriksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bechmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information, Communication &amp; Society</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="802" to="816" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cognition in the Wild</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hutchins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Human3.6M: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Olaru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">;</forename><surname>Isscc Videos</surname></persName>
		</author>
		<author>
			<persName><surname>Yann Lecun</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/watch?v=YzD7Z2yRL7" />
		<title level="m">International Solid-State Circuits Conference 2019: Deep Learning Hardware: Past, Present, and Future</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-19">2019. 19 May 2020</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
	<note>February. Video available at</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The Will to Believe</title>
		<author>
			<persName><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1912">1912</date>
			<publisher>Longmans, Green, and Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">We get the algorithms of our ground truths: Designing referential databases in digital image processing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Studies of Science</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="811" to="840" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pardonnez cette platitude&quot; : de l&apos;int ereË†t des ethnographies de laboratoire pour l&apos; etude des processus algorithmiques</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zilsel</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="315" to="339" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The Constitution of Algorithms: Ground-Truthing, Programming, Formulating</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jaton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Processus frictionnels de mises en bases de donn ees</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jaton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vinck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revue d&apos;anthropologie des connaissances</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="489" to="504" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Politicizing algorithms by other means: Toward inquiries for affective dissensions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jaton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vinck</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted. Manuscript submitted in January 2021 to Perspectives on Science</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The global landscape of AI ethics guidelines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jobin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ienca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vayena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="389" to="399" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Kant</surname></persName>
		</author>
		<title level="m">Groundwork of the Metaphysics of Morals</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1785">1998. 1785</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science in Action -How to Follow Scientists &amp; Engineers through Society</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Politics of Nature</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">EnqueË†te Sur Les Modes D&apos;existence : Une Anthropologie Des Modernes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>La D ecouverte</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>La D ecouverte</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A note on socio-technical graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mauguin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Teil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Studies of Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="57" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Predictive Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2016 | Yann LeCun, Facebook Research. Available at: www.youtube. com/watch?v=Ount2Y4qxQo&amp;t=1072s</title>
		<imprint>
			<date type="published" when="2016-05-19">2016. 19 May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Playing with the data: What legal scholars should learn about machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ohm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCDL Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="653" to="717" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">SelFlow: Self-supervised learning of optical flow</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="4566" to="4575" />
			<date type="published" when="2019-06">2019. 2019. June</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>Long Beach, CA; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">DeepFashion: Powering robust clothes recognition and retrieval with rich annotations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Las Vegas, NV; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016-06-26">2016. 26 June-1 July</date>
			<biblScope unit="page" from="1096" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on computer vision</title>
		<meeting><address><addrLine>Araucuno Park, Chili; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015-12-18">2015. 2015. 18 December</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Unsupervised part-based disentangling of object shape and appearance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bereska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Milbich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-06">2019. 2019. June</date>
			<publisher>IEEE Press</publisher>
			<biblScope unit="page" from="10947" to="10956" />
			<pubPlace>Long Beach, CA; New York</pubPlace>
		</imprint>
	</monogr>
	<note>IEEE/CVF conference on computer vision and pattern recognition</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Values and pragmatic action: the challenges of introducing ethical intelligence in technical design communities</title>
		<author>
			<persName><forename type="first">N</forename><surname>Manders-Huits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Review of Information Ethics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">For Web Images, Creating New Technology to Seek and Find</title>
		<author>
			<persName><forename type="first">J</forename><surname>Markoff</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2012/11/20/science/for-web-images-creating-new-technol-ogy-to-seek-and-find.html" />
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2012-11-19">2012. November 19. 10 July 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Testman</surname></persName>
		</author>
		<ptr target="www.ibm.com/blogs/systems/tackling-bias-in-ai/" />
		<title level="m">Tackling bias in AI</title>
		<imprint>
			<date type="published" when="2019-09-27">2019. 27 September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Object scene flow for autonomous vehicles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Boston, MA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015-06">2015. June</date>
			<biblScope unit="page" from="3061" to="3070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Science-Mart -Privatizing American Science</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mirowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">The Need for Biases in Learning Generalizations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Rutgers University</publisher>
			<pubPlace>New Brunswick</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">CBM-TR-5-Ho</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Principles alone cannot guarantee ethical AI</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mittelstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="501" to="507" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The ethics of algorithms: Mapping the debate</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mittelstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Allo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taddeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2053951716679679</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="567" to="575" />
			<date type="published" when="2011">2011</date>
			<publisher>Curran Associates</publisher>
			<pubPlace>Red Hook, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">The Everyday Life of an Algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Neyland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Palgrave Pivot</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Algorithms of Oppression: How Search Engines Reinforce Racism</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Noble</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>New York University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6464</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">The Black Box Society: The Secret Algorithms That Control Money and Information</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pasquale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The use of machine learning algorithms in recommender systems: a systematic review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Portugal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alencar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="205" to="227" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Bias in AI: A problem recognized but still unresolved</title>
		<author>
			<persName><forename type="first">C</forename><surname>Radfar</surname></persName>
		</author>
		<ptr target="http://social.techcrunch.com/2019/07/25/bias-in-ai-a-problem-recognized-but-still-unresolved/" />
		<imprint>
			<date type="published" when="2019-06-26">2019. June. 26 September 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">TechCrunch</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Beyond Pagerank: Machine learning for static ranking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on World Wide Web</title>
		<meeting>the 15th international conference on World Wide Web<address><addrLine>Edinburgh, Scotland; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006-05">2006. May</date>
			<biblScope unit="page" from="707" to="715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A crucial step for averting AI disasters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shellenbarger</surname></persName>
		</author>
		<ptr target="www.wsj.com/articles/a-crucial-step-for-avoiding-ai-disasters-11550069865" />
	</analytic>
	<monogr>
		<title level="j">Wall Street Journal</title>
		<imprint>
			<date type="published" when="2019-02-13">2019. 13 February. 26 September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Silberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Manyika</surname></persName>
		</author>
		<title level="m">Notes From the AI Frontier: Tackling Bias in AI (and in Humans)</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<publisher>McKinsey Global Institute</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Real-time continuous pose recovery of human hands using convolutional networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international workshop on software fairness</title>
		<editor>
			<persName><forename type="first">Rubin</forename><forename type="middle">J</forename><surname>Verma</surname></persName>
		</editor>
		<meeting>the international workshop on software fairness<address><addrLine>Gothenburg, Sweden; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014. 2018. May</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Fairness definitions explained</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Ethics as an escape from regulation: From &apos;ethics-washing&apos; to ethics-shopping?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wagner</surname></persName>
		</author>
		<editor>Bayamlio glu E, Baraliuc I, Janssens L, et al.</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Amsterdam University Press</publisher>
			<biblScope unit="page" from="84" to="89" />
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Being Profiled</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<title level="m">The Caltech-Ucsd Birds-200-2011 Dataset</title>
		<meeting><address><addrLine>Pasadena</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Self-supervised 3D hand pose estimation through training by fitting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Long Beach, CA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019-06">2019. 2019. June</date>
			<biblScope unit="page" from="10845" to="10954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">WIDER FACE: A face detection benchmark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE conference on computer vision and pattern recognition</title>
		<meeting><address><addrLine>Las Vegas, NV; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016-06-26">2016. 26 June-1 July</date>
			<biblScope unit="page" from="5525" to="5533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Cat head detection -How to effectively exploit shape and texture features</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2008</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Torr</forename><forename type="middle">P</forename><surname>Zisserman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="802" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">From actemes to action: A strongly-supervised representation for detailed action understanding</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on computer vision</title>
		<meeting><address><addrLine>Sydney, Australia; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013-04">2013. 2013. April</date>
			<biblScope unit="page" from="2248" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
